import os
import sys
import cv2
import torch
import numpy as np
import supervision as sv
import subprocess

# åœ¨å¯¼å…¥å…¶ä»–åº“ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡å’Œè­¦å‘Šè¿‡æ»¤
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:128"
os.environ["TRANSFORMERS_VERBOSITY"] = "error"
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["TRANSFORMERS_NO_ADVISORY_WARNINGS"] = "1"

import warnings
import logging
# æŠ‘åˆ¶æ‰€æœ‰ç›¸å…³è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", message=".*weights of the model checkpoint.*")
warnings.filterwarnings("ignore", message=".*torch.load.*weights_only.*")
warnings.filterwarnings("ignore", message=".*deprecated.*")
warnings.filterwarnings("ignore", message=".*Some weights.*were not used.*")
warnings.filterwarnings("ignore", message=".*This IS expected.*")

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.getLogger("transformers").setLevel(logging.ERROR)
logging.getLogger("torch").setLevel(logging.ERROR)
logging.getLogger("transformers.modeling_utils").setLevel(logging.ERROR)

# æ·»åŠ SAM2æ¨¡å—è·¯å¾„
sam2_path = "/home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/sam2_grounding/Grounded-SAM-2"
if sam2_path not in sys.path:
    sys.path.insert(0, sam2_path)

# æ·»åŠ GroundingDINOè·¯å¾„ - ä½¿ç”¨æœ¬åœ°å®‰è£…çš„ç‰ˆæœ¬
grounding_dino_path = "/home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/GroundingDINO-main"
if grounding_dino_path not in sys.path:
    sys.path.insert(0, grounding_dino_path)

from PIL import Image
from sam2.build_sam import build_sam2_video_predictor, build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor

# ä½¿ç”¨æœ¬åœ°GroundingDINO
from groundingdino.util.inference import load_model, load_image, predict
print("âœ“ ä½¿ç”¨æœ¬åœ° GroundingDINO")

# è®¾ç½®utilsè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd()
grounded_sam2_utils = os.path.join(current_dir, 'Grounded-SAM-2', 'utils')
sys.path.insert(0, grounded_sam2_utils)

# å¯¼å…¥utilsæ¨¡å—
from track_utils import sample_points_from_masks

class TrackingHistoryManager:
    """è¿½è¸ªå†å²ç®¡ç†å™¨ï¼Œæé«˜IDè¿ç»­æ€§å¹¶æ£€æŸ¥è¿åŠ¨åˆç†æ€§"""
    def __init__(self, max_missing_frames=3, max_movement_ratio=0.3, max_size_change_ratio=0.5):
        self.object_history = {}  # {object_id: {'positions': [], 'frames': [], 'sizes': [], 'missing_count': 0}}
        self.max_missing_frames = max_missing_frames
        self.max_movement_ratio = max_movement_ratio  # æœ€å¤§ç§»åŠ¨è·ç¦»ç›¸å¯¹äºå›¾åƒå°ºå¯¸çš„æ¯”ä¾‹
        self.max_size_change_ratio = max_size_change_ratio  # æœ€å¤§å°ºå¯¸å˜åŒ–æ¯”ä¾‹
        
    def update_object_position(self, object_id, center_position, frame_idx, mask_area=None):
        """æ›´æ–°ç‰©ä½“ä½ç½®å’Œå°ºå¯¸å†å²"""
        if object_id not in self.object_history:
            self.object_history[object_id] = {
                'positions': [],
                'frames': [],
                'sizes': [],
                'missing_count': 0
            }
        
        self.object_history[object_id]['positions'].append(center_position)
        self.object_history[object_id]['frames'].append(frame_idx)
        if mask_area is not None:
            self.object_history[object_id]['sizes'].append(mask_area)
        self.object_history[object_id]['missing_count'] = 0
        
        # ä¿ç•™æœ€è¿‘çš„10ä¸ªè®°å½•
        if len(self.object_history[object_id]['positions']) > 10:
            self.object_history[object_id]['positions'] = self.object_history[object_id]['positions'][-10:]
            self.object_history[object_id]['frames'] = self.object_history[object_id]['frames'][-10:]
            if self.object_history[object_id]['sizes']:
                self.object_history[object_id]['sizes'] = self.object_history[object_id]['sizes'][-10:]
    
    def predict_next_position(self, object_id):
        """é¢„æµ‹ç‰©ä½“ä¸‹ä¸€å¸§çš„ä½ç½®"""
        if object_id not in self.object_history or len(self.object_history[object_id]['positions']) < 2:
            return None
            
        positions = self.object_history[object_id]['positions']
        if len(positions) >= 2:
            # ç®€å•çš„çº¿æ€§é¢„æµ‹
            last_pos = positions[-1]
            second_last_pos = positions[-2]
            velocity = (last_pos[0] - second_last_pos[0], last_pos[1] - second_last_pos[1])
            predicted_pos = (last_pos[0] + velocity[0], last_pos[1] + velocity[1])
            return predicted_pos
        return positions[-1] if positions else None
    
    def is_movement_reasonable(self, object_id, new_position, image_shape):
        """æ£€æŸ¥ç‰©ä½“ç§»åŠ¨æ˜¯å¦åˆç†"""
        if object_id not in self.object_history or not self.object_history[object_id]['positions']:
            return True  # æ–°ç‰©ä½“ï¼Œæ— æ³•æ¯”è¾ƒ
        
        last_position = self.object_history[object_id]['positions'][-1]
        
        # è®¡ç®—ç§»åŠ¨è·ç¦»
        movement_distance = np.sqrt(
            (new_position[0] - last_position[0])**2 + 
            (new_position[1] - last_position[1])**2
        )
        
        # è®¡ç®—ç›¸å¯¹äºå›¾åƒå°ºå¯¸çš„ç§»åŠ¨æ¯”ä¾‹
        image_diagonal = np.sqrt(image_shape[0]**2 + image_shape[1]**2)
        movement_ratio = movement_distance / image_diagonal
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§åˆç†ç§»åŠ¨è·ç¦»
        is_reasonable = movement_ratio <= self.max_movement_ratio
        
        if not is_reasonable:
            print(f"    âš ï¸  ç‰©ä½“ID {object_id} ç§»åŠ¨è¿‡å¿«: {movement_distance:.1f}åƒç´  "
                  f"(å å›¾åƒå¯¹è§’çº¿{movement_ratio:.1%}ï¼Œè¶…è¿‡é˜ˆå€¼{self.max_movement_ratio:.1%})")
        
        return is_reasonable
    
    def is_size_change_reasonable(self, object_id, new_size):
        """æ£€æŸ¥ç‰©ä½“å°ºå¯¸å˜åŒ–æ˜¯å¦åˆç†"""
        if object_id not in self.object_history or not self.object_history[object_id]['sizes']:
            return True  # æ–°ç‰©ä½“ï¼Œæ— æ³•æ¯”è¾ƒ
        
        last_size = self.object_history[object_id]['sizes'][-1]
        
        # è®¡ç®—å°ºå¯¸å˜åŒ–æ¯”ä¾‹
        if last_size > 0:
            size_change_ratio = abs(new_size - last_size) / last_size
            is_reasonable = size_change_ratio <= self.max_size_change_ratio
            
            if not is_reasonable:
                print(f"    âš ï¸  ç‰©ä½“ID {object_id} å°ºå¯¸å˜åŒ–è¿‡å¤§: {last_size:.0f} â†’ {new_size:.0f} "
                      f"(å˜åŒ–{size_change_ratio:.1%}ï¼Œè¶…è¿‡é˜ˆå€¼{self.max_size_change_ratio:.1%})")
            
            return is_reasonable
        
        return True
    
    def validate_object_consistency(self, object_id, new_position, new_size, image_shape):
        """ç»¼åˆéªŒè¯ç‰©ä½“çš„è¿åŠ¨å’Œå°ºå¯¸å˜åŒ–æ˜¯å¦åˆç†"""
        movement_ok = self.is_movement_reasonable(object_id, new_position, image_shape)
        size_ok = self.is_size_change_reasonable(object_id, new_size)
        
        is_consistent = movement_ok and size_ok
        
        if not is_consistent:
            print(f"    ğŸš« ç‰©ä½“ID {object_id} æ£€æµ‹ä¸ä¸€è‡´ï¼Œå¯èƒ½è¯†åˆ«åˆ°äº†å…¶ä»–ç‰©ä½“")
        
        return is_consistent
    
    def mark_missing(self, object_id):
        """æ ‡è®°ç‰©ä½“åœ¨å½“å‰å¸§ç¼ºå¤±"""
        if object_id in self.object_history:
            self.object_history[object_id]['missing_count'] += 1
    
    def should_keep_tracking(self, object_id):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»§ç»­è¿½è¸ªè¯¥ç‰©ä½“"""
        if object_id not in self.object_history:
            return False
        return self.object_history[object_id]['missing_count'] <= self.max_missing_frames
    
    def cleanup_lost_objects(self):
        """æ¸…ç†ä¸¢å¤±å¤ªä¹…çš„ç‰©ä½“"""
        to_remove = []
        for object_id, history in self.object_history.items():
            if history['missing_count'] > self.max_missing_frames:
                to_remove.append(object_id)
        
        for object_id in to_remove:
            del self.object_history[object_id]
    
    def _get_mask_center(self, mask):
        """è®¡ç®—maskçš„ä¸­å¿ƒç‚¹"""
        if isinstance(mask, torch.Tensor):
            mask = mask.cpu().numpy()
        
        y_indices, x_indices = np.where(mask > 0)
        if len(y_indices) == 0:
            return (0, 0)
        
        center_y = np.mean(y_indices)
        center_x = np.mean(x_indices)
        return (center_x, center_y)

from video_utils import create_video_from_images
from common_utils import CommonUtils
from mask_dictionary_model import MaskDictionaryModel, ObjectInfo
import json
import copy

# This demo shows the continuous object tracking plus reverse tracking with Grounding DINO and SAM 2
"""
Step 1: Environment settings and model initialization
"""
# use bfloat16 for the entire notebook
torch.autocast(device_type="cuda", dtype=torch.bfloat16).__enter__()

if torch.cuda.get_device_properties(0).major >= 8:
    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True

# init sam image predictor and video predictor model
sam2_checkpoint = "/home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/sam2_grounding/Grounded-SAM-2/checkpoints/sam2_hiera_large.pt"
model_cfg = "../sam2/configs/sam2/sam2_hiera_l.yaml"
device = "cuda" if torch.cuda.is_available() else "cpu"
print("device", device)

video_predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint)
sam2_image_model = build_sam2(model_cfg, sam2_checkpoint, device=device)
image_predictor = SAM2ImagePredictor(sam2_image_model)

# åˆå§‹åŒ–æœ¬åœ° GroundingDINO æ¨¡å‹
GROUNDING_DINO_CONFIG = "/home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/GroundingDINO-main/groundingdino/config/GroundingDINO_SwinT_OGC.py"
GROUNDING_DINO_CHECKPOINT = "/home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/sam2_grounding/Grounded-SAM-2/code_ozh/weights/groundingdino_swint_ogc.pth"

print(f"æ­£åœ¨åŠ è½½ GroundingDINO æ¨¡å‹...")
print(f"é…ç½®æ–‡ä»¶: {GROUNDING_DINO_CONFIG}")
print(f"æƒé‡æ–‡ä»¶: {GROUNDING_DINO_CHECKPOINT}")

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if not os.path.exists(GROUNDING_DINO_CONFIG):
    raise FileNotFoundError(f"GroundingDINO é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {GROUNDING_DINO_CONFIG}")

if not os.path.exists(GROUNDING_DINO_CHECKPOINT):
    print(f"âœ— GroundingDINO æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {GROUNDING_DINO_CHECKPOINT}")
    print("æç¤º: è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²ä¸‹è½½åˆ°æ­£ç¡®ä½ç½®")
    print("æ‚¨å¯ä»¥ä»ä»¥ä¸‹ä½ç½®å¤åˆ¶ç°æœ‰çš„æ¨¡å‹æ–‡ä»¶:")
    print("  - /home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/sam2_picture/GroundingDINO_sam2/gdino_checkpoints/groundingdino_swint_ogc.pth")
    print("  - /home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/sam2_grounding/Grounded-SAM-2/gdino_checkpoints/groundingdino_swint_ogc.pth")
    
    # å°è¯•ä»å…¶ä»–ä½ç½®å¤åˆ¶
    import shutil
    source_paths = [
        "/home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/sam2_picture/GroundingDINO_sam2/gdino_checkpoints/groundingdino_swint_ogc.pth",
        "/home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/sam2_grounding/Grounded-SAM-2/gdino_checkpoints/groundingdino_swint_ogc.pth"
    ]
    
    for source_path in source_paths:
        if os.path.exists(source_path):
            print(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œæ­£åœ¨ä» {source_path} å¤åˆ¶...")
            os.makedirs(os.path.dirname(GROUNDING_DINO_CHECKPOINT), exist_ok=True)
            shutil.copy2(source_path, GROUNDING_DINO_CHECKPOINT)
            print(f"âœ“ æ¨¡å‹æ–‡ä»¶å·²å¤åˆ¶åˆ° {GROUNDING_DINO_CHECKPOINT}")
            break
    else:
        raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ° GroundingDINO æƒé‡æ–‡ä»¶")

try:
    grounding_model = load_model(
        model_config_path=GROUNDING_DINO_CONFIG,
        model_checkpoint_path=GROUNDING_DINO_CHECKPOINT,
        device=device
    )
    print("âœ“ æœ¬åœ° GroundingDINO æ¨¡å‹åŠ è½½æˆåŠŸ")
except Exception as e:
    print(f"âœ— GroundingDINO æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    raise RuntimeError("æ— æ³•åŠ è½½ GroundingDINO æ¨¡å‹")


# setup the input image and text prompt for SAM 2 and Grounding DINO
# VERY important: text queries need to be lowercased + end with a dot
# é’ˆå¯¹holeçš„ç²¾ç¡®è¯†åˆ«è¿›è¡Œä¼˜åŒ–ï¼Œä½¿ç”¨æ›´å¹¿æ³›çš„æè¿°è¯
text = "hole. opening. cavity. circular hole. dark hole."

# Video processing paths
input_video_dir = "/home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/input/videos"
# `video_dir` a directory of JPEG frames with filenames like `<frame_index>.jpg` (5-digit format with leading zeros)
video_dir = "/home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/output/videos_ffmpeg"
# 'output_dir' is the directory to save the annotated frames
output_dir = "/home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/output/videos_masks"
# 'output_video_path' is the path to save the final video
output_video_path = "/home/colab/anaconda3/envs/sam2_env_ozh/program_ozh/output/videos/output.mp4"

def clear_directory(directory_path):
    """
    æ¸…ç©ºæŒ‡å®šç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•
    
    Args:
        directory_path: è¦æ¸…ç©ºçš„ç›®å½•è·¯å¾„
    """
    if os.path.exists(directory_path):
        import shutil
        for filename in os.listdir(directory_path):
            file_path = os.path.join(directory_path, filename)
            try:
                if os.path.isfile(file_path) or os.path.islink(file_path):
                    os.unlink(file_path)
                elif os.path.isdir(file_path):
                    shutil.rmtree(file_path)
            except Exception as e:
                print(f"    âš ï¸  åˆ é™¤ {file_path} æ—¶å‡ºé”™: {e}")
        print(f"    âœ…  å·²æ¸…ç©ºç›®å½•: {directory_path}")
    else:
        print(f"    â„¹ï¸  ç›®å½•ä¸å­˜åœ¨: {directory_path}")

def extract_frames_with_ffmpeg(input_video_path, output_frames_dir, fps=None):
    """
    ä½¿ç”¨FFmpegä»è§†é¢‘ä¸­æå–å¸§
    Args:
        input_video_path: è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_frames_dir: è¾“å‡ºå¸§å›¾åƒçš„ç›®å½•
        fps: æå–å¸§ç‡ï¼Œå¦‚æœä¸ºNoneåˆ™æå–æ‰€æœ‰å¸§
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_frames_dir, exist_ok=True)
    
    # æ„å»ºFFmpegå‘½ä»¤
    if fps is not None:
        # æŒ‡å®šå¸§ç‡æå–
        cmd = [
            'ffmpeg', '-i', input_video_path,
            '-vf', f'fps={fps}',
            '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            os.path.join(output_frames_dir, '%05d.jpg')  # ğŸ”§ æ”¹ä¸º5ä½æ•°æ ¼å¼
        ]
    else:
        # æå–æ‰€æœ‰å¸§
        cmd = [
            'ffmpeg', '-i', input_video_path,
            '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            os.path.join(output_frames_dir, '%05d.jpg')  # ğŸ”§ æ”¹ä¸º5ä½æ•°æ ¼å¼
        ]
    
    print(f"ğŸ¬ æ­£åœ¨ä½¿ç”¨FFmpegæå–è§†é¢‘å¸§...")
    print(f"è¾“å…¥è§†é¢‘: {input_video_path}")
    print(f"è¾“å‡ºç›®å½•: {output_frames_dir}")
    if fps:
        print(f"æå–å¸§ç‡: {fps} fps")
    
    try:
        # æ‰§è¡ŒFFmpegå‘½ä»¤
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        
        # ç»Ÿè®¡æå–çš„å¸§æ•°
        extracted_files = [f for f in os.listdir(output_frames_dir) 
                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        extracted_files.sort(key=lambda x: int(os.path.splitext(x)[0]))
        
        print(f"âœ“ æˆåŠŸæå–äº† {len(extracted_files)} å¸§å›¾åƒ")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âœ— FFmpegæ‰§è¡Œå¤±è´¥: {e}")
        print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
        return False
    except Exception as e:
        print(f"âœ— è§†é¢‘å¸§æå–å¤±è´¥: {e}")
        return False

def find_video_file(input_dir):
    """
    åœ¨è¾“å…¥ç›®å½•ä¸­æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
    """
    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm']
    
    if not os.path.exists(input_dir):
        print(f"âœ— è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return None
    
    video_files = []
    for file in os.listdir(input_dir):
        if any(file.lower().endswith(ext) for ext in video_extensions):
            video_files.append(os.path.join(input_dir, file))
    
    if not video_files:
        print(f"âœ— åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
        print(f"æ”¯æŒçš„è§†é¢‘æ ¼å¼: {', '.join(video_extensions)}")
        return None
    
    if len(video_files) > 1:
        print(f"âš ï¸  æ‰¾åˆ°å¤šä¸ªè§†é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª: {video_files[0]}")
        for i, vf in enumerate(video_files):
            print(f"  {i+1}. {os.path.basename(vf)}")
    
    return video_files[0]

def get_video_framerate(video_path):
    """
    è·å–è§†é¢‘çš„å¸§ç‡
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
    Returns:
        float: è§†é¢‘å¸§ç‡ï¼Œå¤±è´¥æ—¶è¿”å›25.0ä½œä¸ºé»˜è®¤å€¼
    """
    try:
        import cv2
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âš ï¸  æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
            return 25.0
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        cap.release()
        
        if fps > 0:
            print(f"ğŸ“Š æ£€æµ‹åˆ°è¾“å…¥è§†é¢‘å¸§ç‡: {fps:.2f} fps")
            return fps
        else:
            print(f"âš ï¸  æ— æ³•è·å–è§†é¢‘å¸§ç‡ï¼Œä½¿ç”¨é»˜è®¤å€¼: 25.0 fps")
            return 25.0
            
    except Exception as e:
        print(f"âš ï¸  è·å–è§†é¢‘å¸§ç‡å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼: 25.0 fps")
        return 25.0

def validate_hole_features(mask, bbox, image_shape, confidence, image_array=None):
    """
    éªŒè¯æ£€æµ‹åˆ°çš„ç‰©ä½“æ˜¯å¦çœŸçš„æ˜¯holeï¼ˆå¢å¼ºç‰ˆï¼šåŒºåˆ†çœŸholeå’Œå¹³é¢ç‰©ä½“ï¼‰
    Args:
        mask: ç‰©ä½“çš„mask
        bbox: è¾¹ç•Œæ¡† [x1, y1, x2, y2]
        image_shape: å›¾åƒå°ºå¯¸ (H, W)
        confidence: æ£€æµ‹ç½®ä¿¡åº¦
        image_array: åŸå§‹å›¾åƒæ•°ç»„ï¼Œç”¨äºçº¹ç†å’Œæ·±åº¦åˆ†æ
    Returns:
        is_valid_hole: bool, æ˜¯å¦æ˜¯æœ‰æ•ˆçš„hole
        hole_score: float, holeçš„ç½®ä¿¡åº¦åˆ†æ•° (0-1)
        validation_info: dict, éªŒè¯ä¿¡æ¯
    """
    H, W = image_shape
    x1, y1, x2, y2 = bbox
    
    # ğŸ”§ ç¡®ä¿maskå°ºå¯¸ä¸å›¾åƒå°ºå¯¸åŒ¹é…ï¼ˆå…³é”®ä¿®å¤ï¼‰
    if mask.shape != (H, W):
        #print(f"    âš ï¸  è°ƒæ•´maskå°ºå¯¸: {mask.shape} â†’ ({H}, {W})")
        if mask.shape[0] > H or mask.shape[1] > W:
            # å¦‚æœmaskæ¯”å›¾åƒå¤§ï¼Œè£å‰ªmask
            mask = mask[:H, :W]
        else:
            # å¦‚æœmaskæ¯”å›¾åƒå°ï¼Œå¡«å……mask
            new_mask = np.zeros((H, W), dtype=mask.dtype)
            new_mask[:mask.shape[0], :mask.shape[1]] = mask
            mask = new_mask
    
    # ğŸ”§ ç¡®ä¿image_arrayå°ºå¯¸åŒ¹é…
    if image_array is not None and image_array.shape[:2] != (H, W):
        print(f"    âš ï¸  è°ƒæ•´image_arrayå°ºå¯¸: {image_array.shape} â†’ ({H}, {W}, ...)")
        # ä½¿ç”¨OpenCV resizeè°ƒæ•´å›¾åƒå°ºå¯¸
        if len(image_array.shape) == 3:
            image_array = cv2.resize(image_array, (W, H))
        else:
            image_array = cv2.resize(image_array, (W, H))
    
    # åŸºç¡€ç‰¹å¾è®¡ç®—
    mask_area = mask.sum()
    bbox_area = (x2 - x1) * (y2 - y1)
    
    # 1. é¢ç§¯æ¯”ä¾‹éªŒè¯ï¼ˆholeä¸åº”è¯¥å¤ªå¤§ä¹Ÿä¸åº”è¯¥å¤ªå°ï¼‰
    image_area = H * W
    area_ratio = mask_area / image_area
    
    # holeçš„åˆç†é¢ç§¯èŒƒå›´ï¼š0.1% ~ 15%
    area_score = 0.0
    if 0.001 <= area_ratio <= 0.15:
        # åœ¨åˆç†èŒƒå›´å†…ï¼Œç»™äºˆé«˜åˆ†
        if 0.001 <= area_ratio <= 0.05:
            area_score = 1.0  # æœ€ç†æƒ³çš„holeå¤§å°
        else:
            area_score = 0.8  # è¾ƒå¤§holeï¼Œä»ç„¶åˆç†
    else:
        area_score = 0.1  # ä¸åˆç†çš„å¤§å°
    
    # 2. å½¢çŠ¶ç´§å‡‘åº¦éªŒè¯ï¼ˆholeé€šå¸¸æ¯”è¾ƒç´§å‡‘ï¼Œæ¥è¿‘åœ†å½¢ï¼‰
    if bbox_area > 0:
        compactness = mask_area / bbox_area
    else:
        compactness = 0
    
    # holeçš„compactnessé€šå¸¸åœ¨0.3-1.0ä¹‹é—´
    compactness_score = min(1.0, max(0.0, compactness))
    
    # 3. å®½é«˜æ¯”éªŒè¯ï¼ˆholeé€šå¸¸æ¥è¿‘æ­£æ–¹å½¢æˆ–åœ†å½¢ï¼‰
    bbox_width = x2 - x1
    bbox_height = y2 - y1
    if bbox_height > 0:
        aspect_ratio = bbox_width / bbox_height
    else:
        aspect_ratio = 1.0
    
    # ç†æƒ³çš„å®½é«˜æ¯”åœ¨0.5-2.0ä¹‹é—´
    if 0.5 <= aspect_ratio <= 2.0:
        aspect_score = 1.0
    elif 0.3 <= aspect_ratio <= 3.0:
        aspect_score = 0.7
    else:
        aspect_score = 0.3
    
    # 4. æ£€æµ‹ç½®ä¿¡åº¦æƒé‡
    confidence_score = min(1.0, confidence * 2)  # æ”¾å¤§ç½®ä¿¡åº¦å½±å“
    
    # 5. ä½ç½®éªŒè¯ï¼ˆholeé€šå¸¸ä¸åœ¨å›¾åƒè¾¹ç¼˜ï¼‰
    center_x = (x1 + x2) / 2
    center_y = (y1 + y2) / 2
    
    # è®¡ç®—åˆ°è¾¹ç¼˜çš„æœ€å°è·ç¦»æ¯”ä¾‹
    edge_dist_ratio = min(
        center_x / W, 
        (W - center_x) / W,
        center_y / H, 
        (H - center_y) / H
    )
    
    # å¦‚æœå¤ªé è¿‘è¾¹ç¼˜ï¼Œé™ä½åˆ†æ•°
    if edge_dist_ratio > 0.1:
        edge_score = 1.0
    elif edge_dist_ratio > 0.05:
        edge_score = 0.8
    else:
        edge_score = 0.5
    
    # 6. ğŸ” æ–°å¢ï¼šæ·±åº¦å’Œç«‹ä½“ç‰¹å¾æ£€æµ‹
    depth_score = 0.5  # é»˜è®¤ä¸­æ€§åˆ†æ•°
    texture_score = 0.5  # é»˜è®¤ä¸­æ€§åˆ†æ•°
    edge_gradient_score = 0.5  # é»˜è®¤ä¸­æ€§åˆ†æ•°
    
    if image_array is not None:
        try:
            # æå–holeåŒºåŸŸçš„å›¾åƒ
            x1_int, y1_int, x2_int, y2_int = int(x1), int(y1), int(x2), int(y2)
            x1_int = max(0, x1_int)
            y1_int = max(0, y1_int)
            x2_int = min(W, x2_int)
            y2_int = min(H, y2_int)
            
            hole_region = image_array[y1_int:y2_int, x1_int:x2_int]
            mask_region = mask[y1_int:y2_int, x1_int:x2_int]
            
            # ğŸ”§ ç¡®ä¿å°ºå¯¸åŒ¹é…ï¼ˆå…³é”®ä¿®å¤ï¼‰
            if hole_region.shape[:2] != mask_region.shape:
                print(f"    âš ï¸  å°ºå¯¸ä¸åŒ¹é…: hole_region{hole_region.shape} vs mask_region{mask_region.shape}")
                # è°ƒæ•´mask_regionå°ºå¯¸ä»¥åŒ¹é…hole_region
                if len(mask_region.shape) == 2:
                    mask_region = mask_region[:hole_region.shape[0], :hole_region.shape[1]]
                else:
                    mask_region = mask_region[:hole_region.shape[0], :hole_region.shape[1], :]
            
            if hole_region.size > 0 and mask_region.sum() > 10:
                # 6a. äº®åº¦åˆ†æï¼šçœŸholeé€šå¸¸æ¯”å‘¨å›´æ›´æš—
                # ğŸ”§ ç¡®ä¿mask_regionæ˜¯å¸ƒå°”ç±»å‹ç”¨äºç´¢å¼•
                mask_region_bool = mask_region.astype(bool)
                hole_pixels = hole_region[mask_region_bool]
                if len(hole_pixels) > 0:
                    # è½¬æ¢ä¸ºç°åº¦å€¼è¿›è¡Œäº®åº¦åˆ†æ
                    if len(hole_pixels.shape) == 2:  # å·²ç»æ˜¯ç°åº¦
                        hole_brightness = np.mean(hole_pixels)
                    else:  # RGBå›¾åƒ
                        hole_brightness = np.mean(np.mean(hole_pixels, axis=1))
                    
                    # è®¡ç®—å‘¨å›´åŒºåŸŸçš„äº®åº¦ä½œä¸ºå¯¹æ¯”
                    padding = 10
                    y1_expand = max(0, y1_int - padding)
                    y2_expand = min(H, y2_int + padding)
                    x1_expand = max(0, x1_int - padding)
                    x2_expand = min(W, x2_int + padding)
                    
                    surrounding_region = image_array[y1_expand:y2_expand, x1_expand:x2_expand]
                    surrounding_mask = np.ones((y2_expand-y1_expand, x2_expand-x1_expand), dtype=bool)
                    
                    # æ’é™¤holeåŒºåŸŸæœ¬èº«
                    hole_y_start = y1_int - y1_expand
                    hole_y_end = hole_y_start + (y2_int - y1_int)
                    hole_x_start = x1_int - x1_expand
                    hole_x_end = hole_x_start + (x2_int - x1_int)
                    
                    if (hole_y_end <= surrounding_mask.shape[0] and 
                        hole_x_end <= surrounding_mask.shape[1]):
                        surrounding_mask[hole_y_start:hole_y_end, hole_x_start:hole_x_end] = False
                    
                    # ğŸ”§ ç¡®ä¿surrounding_maskæ˜¯å¸ƒå°”ç±»å‹ç”¨äºç´¢å¼•
                    surrounding_mask_bool = surrounding_mask.astype(bool)
                    surrounding_pixels = surrounding_region[surrounding_mask_bool]
                    if len(surrounding_pixels) > 0:
                        if len(surrounding_pixels.shape) == 2:
                            surrounding_brightness = np.mean(surrounding_pixels)
                        else:
                            surrounding_brightness = np.mean(np.mean(surrounding_pixels, axis=1))
                        
                        # çœŸholeåº”è¯¥æ¯”å‘¨å›´æš—
                        brightness_ratio = hole_brightness / (surrounding_brightness + 1e-6)
                        if brightness_ratio < 0.7:  # holeæ¯”å‘¨å›´æš—30%ä»¥ä¸Š
                            depth_score = 1.0
                        elif brightness_ratio < 0.85:  # holeæ¯”å‘¨å›´æš—15%ä»¥ä¸Š
                            depth_score = 0.8
                        elif brightness_ratio < 0.95:  # holeæ¯”å‘¨å›´æš—5%ä»¥ä¸Š
                            depth_score = 0.6
                        else:  # holeä¸å¤Ÿæš—ï¼Œå¯èƒ½æ˜¯å¹³é¢
                            depth_score = 0.2
                
                # 6b. çº¹ç†å¤æ‚åº¦åˆ†æï¼šçœŸholeå†…éƒ¨çº¹ç†è¾ƒç®€å•ï¼Œå¹³é¢ç‰©ä½“çº¹ç†å¤æ‚
                if len(hole_pixels) > 50:  # ç¡®ä¿æœ‰è¶³å¤Ÿåƒç´ è¿›è¡Œåˆ†æ
                    # è®¡ç®—holeåŒºåŸŸçš„æ ‡å‡†å·®ï¼ˆçº¹ç†å¤æ‚åº¦æŒ‡æ ‡ï¼‰
                    if len(hole_pixels.shape) == 2:
                        hole_std = np.std(hole_pixels)
                    else:
                        # å¯¹RGBå„é€šé“è®¡ç®—æ ‡å‡†å·®çš„å¹³å‡å€¼
                        hole_std = np.mean([np.std(hole_pixels[:, i]) for i in range(hole_pixels.shape[1])])
                    
                    # çœŸholeå†…éƒ¨ç›¸å¯¹å‡åŒ€ï¼ˆä½æ ‡å‡†å·®ï¼‰ï¼Œå¹³é¢ç‰©ä½“çº¹ç†å¤æ‚ï¼ˆé«˜æ ‡å‡†å·®ï¼‰
                    if hole_std < 15:  # å¾ˆå‡åŒ€ï¼Œå¯èƒ½æ˜¯çœŸhole
                        texture_score = 1.0
                    elif hole_std < 25:  # æ¯”è¾ƒå‡åŒ€
                        texture_score = 0.8
                    elif hole_std < 40:  # ä¸­ç­‰å¤æ‚åº¦
                        texture_score = 0.6
                    else:  # çº¹ç†å¤æ‚ï¼Œå¯èƒ½æ˜¯æœ¨æ¿ç­‰å¹³é¢ç‰©ä½“
                        texture_score = 0.2
                
                # 6c. è¾¹ç¼˜æ¢¯åº¦åˆ†æï¼šçœŸholeè¾¹ç¼˜æœ‰æ˜æ˜¾çš„æ·±åº¦è¿‡æ¸¡
                edge_gradient_score = 0.5
                try:
                    # è®¡ç®—holeè¾¹ç¼˜çš„æ¢¯åº¦å˜åŒ–
                    gray_region = cv2.cvtColor(hole_region, cv2.COLOR_RGB2GRAY) if len(hole_region.shape) == 3 else hole_region
                    
                    # ä½¿ç”¨Sobelç®—å­è®¡ç®—æ¢¯åº¦
                    grad_x = cv2.Sobel(gray_region, cv2.CV_64F, 1, 0, ksize=3)
                    grad_y = cv2.Sobel(gray_region, cv2.CV_64F, 0, 1, ksize=3)
                    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
                    
                    # åœ¨maskè¾¹ç¼˜è®¡ç®—æ¢¯åº¦å¼ºåº¦
                    kernel = np.ones((3,3), np.uint8)
                    mask_edge = cv2.morphologyEx(mask_region.astype(np.uint8), cv2.MORPH_GRADIENT, kernel)
                    
                    # ğŸ”§ ç¡®ä¿æ¢¯åº¦å’Œmaskè¾¹ç¼˜å°ºå¯¸åŒ¹é…
                    if gradient_magnitude.shape != mask_edge.shape:
                        #print(f"    âš ï¸  æ¢¯åº¦å’Œmaskå°ºå¯¸ä¸åŒ¹é…: gradient{gradient_magnitude.shape} vs mask_edge{mask_edge.shape}")
                        # è°ƒæ•´mask_edgeå°ºå¯¸ä»¥åŒ¹é…gradient_magnitude
                        min_h = min(gradient_magnitude.shape[0], mask_edge.shape[0])
                        min_w = min(gradient_magnitude.shape[1], mask_edge.shape[1])
                        mask_edge = mask_edge[:min_h, :min_w]
                        gradient_magnitude = gradient_magnitude[:min_h, :min_w]
                    
                    if mask_edge.sum() > 0:
                        # ğŸ”§ ç¡®ä¿mask_edgeæ˜¯å¸ƒå°”ç±»å‹ç”¨äºç´¢å¼•
                        mask_edge_bool = (mask_edge > 0).astype(bool)
                        edge_gradient = gradient_magnitude[mask_edge_bool]
                        if len(edge_gradient) > 0:
                            avg_edge_gradient = np.mean(edge_gradient)
                            
                            # çœŸholeè¾¹ç¼˜æ¢¯åº¦åº”è¯¥è¾ƒå¼ºï¼ˆæ·±åº¦å˜åŒ–æ˜æ˜¾ï¼‰
                            if avg_edge_gradient > 30:  # å¼ºæ¢¯åº¦ï¼Œè¡¨ç¤ºæ·±åº¦å˜åŒ–
                                edge_gradient_score = 1.0
                            elif avg_edge_gradient > 20:  # ä¸­ç­‰æ¢¯åº¦
                                edge_gradient_score = 0.8
                            elif avg_edge_gradient > 10:  # å¼±æ¢¯åº¦
                                edge_gradient_score = 0.6
                            else:  # å‡ ä¹æ— æ¢¯åº¦ï¼Œå¹³é¢ç‰¹å¾
                                edge_gradient_score = 0.2
                
                except Exception as e:
                    print(f"    âš ï¸  è¾¹ç¼˜æ¢¯åº¦åˆ†æå‡ºé”™: {e}")
                    edge_gradient_score = 0.5
                        
        except Exception as e:
            print(f"    âš ï¸  æ·±åº¦åˆ†æå‡ºé”™: {e}")
            depth_score = 0.5
            texture_score = 0.5
            edge_gradient_score = 0.5
    
    # 7. åœ†åº¦åˆ†æï¼šçœŸholeæ›´æ¥è¿‘åœ†å½¢
    circularity_score = 0.5
    try:
        # è®¡ç®—maskçš„å‘¨é•¿
        contour_length = 0
        mask_uint8 = mask.astype(np.uint8)
        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            contour_length = cv2.arcLength(contours[0], True)
            if contour_length > 0:
                # åœ†åº¦ = 4Ï€ * é¢ç§¯ / å‘¨é•¿Â²
                circularity = 4 * np.pi * mask_area / (contour_length * contour_length)
                circularity = min(1.0, circularity)  # é™åˆ¶åœ¨1ä»¥å†…
                
                if circularity > 0.7:  # éå¸¸æ¥è¿‘åœ†å½¢
                    circularity_score = 1.0
                elif circularity > 0.5:  # æ¯”è¾ƒæ¥è¿‘åœ†å½¢
                    circularity_score = 0.8
                elif circularity > 0.3:  # æœ‰ç‚¹æ¥è¿‘åœ†å½¢
                    circularity_score = 0.6
                else:  # ä¸å¤ªåƒåœ†å½¢
                    circularity_score = 0.3
    except Exception as e:
        print(f"    âš ï¸  åœ†åº¦åˆ†æå‡ºé”™: {e}")
        circularity_score = 0.5
    
    # 8. ğŸ” æ–°å¢ï¼šé¢œè‰²äº®åº¦å’Œå¯¹æ¯”åº¦åˆ†æï¼ˆé‡è¦ï¼šåŒºåˆ†æœ¨æ¿å’Œholeï¼‰
    brightness_score = 0.5
    contrast_score = 0.5
    
    if image_array is not None:
        try:
            x1, y1, x2, y2 = map(int, bbox)
            roi = image_array[y1:y2, x1:x2]
            
            if roi.size > 0:
                # è®¡ç®—åŒºåŸŸå†…çš„å¹³å‡äº®åº¦
                gray_roi = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY) if len(roi.shape) == 3 else roi
                mean_brightness = np.mean(gray_roi)
                
                # è®¡ç®—å‘¨å›´åŒºåŸŸçš„å¹³å‡äº®åº¦è¿›è¡Œå¯¹æ¯”
                padding = 30
                y1_ext = max(0, y1 - padding)
                y2_ext = min(image_array.shape[0], y2 + padding)
                x1_ext = max(0, x1 - padding)
                x2_ext = min(image_array.shape[1], x2 + padding)
                
                surrounding_roi = image_array[y1_ext:y2_ext, x1_ext:x2_ext]
                if surrounding_roi.size > 0:
                    surrounding_gray = cv2.cvtColor(surrounding_roi, cv2.COLOR_RGB2GRAY) if len(surrounding_roi.shape) == 3 else surrounding_roi
                    surrounding_brightness = np.mean(surrounding_gray)
                    
                    # çœŸholeåº”è¯¥æ¯”å‘¨å›´åŒºåŸŸæš—å¾—å¤šï¼ˆè¿™æ˜¯å…³é”®åŒºåˆ«ç‚¹ï¼‰
                    brightness_diff = surrounding_brightness - mean_brightness
                    if brightness_diff > 60:  # æ˜¾è‘—æ›´æš—ï¼Œå¾ˆå¯èƒ½æ˜¯hole
                        brightness_score = 1.0
                    elif brightness_diff > 40:  # è¾ƒæš—ï¼Œå¯èƒ½æ˜¯hole
                        brightness_score = 0.8
                    elif brightness_diff > 20:  # ç¨æš—ï¼Œæœ‰å¯èƒ½æ˜¯hole
                        brightness_score = 0.6
                    elif brightness_diff > 5:   # ç¨å¾®æš—ä¸€äº›
                        brightness_score = 0.3
                    else:  # äº®åº¦ç›¸åŒæˆ–æ›´äº®ï¼Œå¾ˆå¯èƒ½æ˜¯å¹³é¢ç‰©ä½“ï¼ˆå¦‚æœ¨æ¿ï¼‰
                        brightness_score = 0.1
                        
                    # è®¡ç®—å¯¹æ¯”åº¦ï¼ˆholeå†…éƒ¨é€šå¸¸å¯¹æ¯”åº¦è¾ƒä½ï¼Œæ¯”è¾ƒå‡åŒ€æš—ï¼‰
                    roi_std = np.std(gray_roi)
                    if roi_std < 8:  # å¯¹æ¯”åº¦å¾ˆä½ï¼Œå‡åŒ€æš—åŒºï¼Œå¾ˆåƒhole
                        contrast_score = 1.0
                    elif roi_std < 15:  # å¯¹æ¯”åº¦è¾ƒä½ï¼Œåƒhole
                        contrast_score = 0.8
                    elif roi_std < 25:  # å¯¹æ¯”åº¦ä¸­ç­‰
                        contrast_score = 0.6
                    elif roi_std < 35:  # å¯¹æ¯”åº¦è¾ƒé«˜ï¼Œå¯èƒ½æ˜¯çº¹ç†
                        contrast_score = 0.3
                    else:  # å¯¹æ¯”åº¦å¾ˆé«˜ï¼Œå¾ˆå¯èƒ½æ˜¯å¤æ‚çº¹ç†ï¼ˆå¦‚æœ¨æ¿ï¼‰
                        contrast_score = 0.1
        except Exception as e:
            print(f"    âš ï¸  äº®åº¦å¯¹æ¯”åº¦åˆ†æå‡ºé”™: {e}")
            brightness_score = 0.5
            contrast_score = 0.5
    
    # ç»¼åˆè¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼Œé‡ç‚¹å¼ºåŒ–åŒºåˆ†æœ¨æ¿å’Œholeçš„ç‰¹å¾ï¼‰
    weights = {
        'area': 0.08,
        'compactness': 0.08,
        'aspect': 0.06,
        'confidence': 0.06,
        'edge': 0.03,
        'depth': 0.25,        # æ·±åº¦ç‰¹å¾æƒé‡é«˜
        'texture': 0.12,      # çº¹ç†ç‰¹å¾
        'edge_gradient': 0.08, # è¾¹ç¼˜æ¢¯åº¦ç‰¹å¾
        'circularity': 0.04,   # åœ†åº¦ç‰¹å¾
        'brightness': 0.15,    # ğŸ”¥æ–°å¢ï¼šäº®åº¦å¯¹æ¯”ï¼Œå…³é”®åŒºåˆ†ç‰¹å¾
        'contrast': 0.05       # ğŸ”¥æ–°å¢ï¼šå¯¹æ¯”åº¦ï¼Œè¾…åŠ©åŒºåˆ†ç‰¹å¾
    }
    
    hole_score = (
        weights['area'] * area_score +
        weights['compactness'] * compactness_score +
        weights['aspect'] * aspect_score +
        weights['confidence'] * confidence_score +
        weights['edge'] * edge_score +
        weights['depth'] * depth_score +
        weights['texture'] * texture_score +
        weights['edge_gradient'] * edge_gradient_score +
        weights['circularity'] * circularity_score +
        weights['brightness'] * brightness_score +
        weights['contrast'] * contrast_score
    )
    
    # è®¾ç½®éªŒè¯é˜ˆå€¼ï¼ˆé€‚åº¦é™ä½é˜ˆå€¼ï¼Œå¹³è¡¡æ£€æµ‹ç‡å’Œå‡†ç¡®ç‡ï¼‰
    validation_threshold = 0.31314  # é™ä½é˜ˆå€¼ï¼Œç¡®ä¿èƒ½æ£€æµ‹åˆ°hole
    is_valid_hole = hole_score >= validation_threshold
    
    # è¯¦ç»†éªŒè¯ä¿¡æ¯
    validation_info = {
        'area_ratio': area_ratio,
        'area_score': area_score,
        'compactness': compactness,
        'compactness_score': compactness_score,
        'aspect_ratio': aspect_ratio,
        'aspect_score': aspect_score,
        'confidence_score': confidence_score,
        'edge_distance_ratio': edge_dist_ratio,
        'edge_score': edge_score,
        'depth_score': depth_score,
        'texture_score': texture_score,
        'edge_gradient_score': edge_gradient_score,
        'circularity_score': circularity_score,
        'brightness_score': brightness_score,  # ğŸ†• æ–°å¢äº®åº¦ç‰¹å¾
        'contrast_score': contrast_score,      # ğŸ†• æ–°å¢å¯¹æ¯”åº¦ç‰¹å¾
        'final_score': hole_score,
        'threshold': validation_threshold,
        'bbox_size': (bbox_width, bbox_height),
        'mask_area': int(mask_area)
    }
    
    return is_valid_hole, hole_score, validation_info

# è‡ªåŠ¨è§†é¢‘å¸§æå–
print("\n" + "="*50)
print("ğŸ¬ å¼€å§‹è§†é¢‘å¸§æå–é˜¶æ®µ")
print("="*50)

# æŸ¥æ‰¾è¾“å…¥è§†é¢‘æ–‡ä»¶
input_video_path = find_video_file(input_video_dir)
if input_video_path is None:
    raise FileNotFoundError(f"æ— æ³•åœ¨ {input_video_dir} ä¸­æ‰¾åˆ°è§†é¢‘æ–‡ä»¶")

print(f"ğŸ“ æ‰¾åˆ°è¾“å…¥è§†é¢‘: {os.path.basename(input_video_path)}")

# è·å–è¾“å…¥è§†é¢‘çš„å¸§ç‡
input_video_fps = get_video_framerate(input_video_path)

# æ¸…ç©ºå¹¶é‡æ–°åˆ›å»ºè§†é¢‘å¸§ç›®å½•
print("ğŸ§¹ æ¸…ç©ºè§†é¢‘å¸§ç›®å½•...")
clear_directory(video_dir)
os.makedirs(video_dir, exist_ok=True)
print("âœ… è§†é¢‘å¸§ç›®å½•å·²æ¸…ç©º")

# æå–è§†é¢‘å¸§
success = extract_frames_with_ffmpeg(input_video_path, video_dir)
if not success:
    raise RuntimeError("è§†é¢‘å¸§æå–å¤±è´¥")

print("\n" + "="*50)
print("ğŸ” å¼€å§‹ç‰©ä½“æ£€æµ‹ä¸è·Ÿè¸ªé˜¶æ®µ")
print("="*50)

# create the output directory
mask_data_dir = os.path.join(output_dir, "mask_data")
json_data_dir = os.path.join(output_dir, "json_data")
result_dir = os.path.join(output_dir, "result")
CommonUtils.creat_dirs(mask_data_dir)
CommonUtils.creat_dirs(json_data_dir)
CommonUtils.creat_dirs(result_dir)

print("\nğŸ§¹ æ¸…ç©ºè¾“å‡ºç›®å½•...")
clear_directory(mask_data_dir)
clear_directory(json_data_dir)
clear_directory(result_dir)
print("âœ… è¾“å‡ºç›®å½•å·²æ¸…ç©ºå®Œæˆ\n")
# scan all the JPEG frame names in this directory
frame_names = [
    p for p in os.listdir(video_dir)
    if os.path.splitext(p)[-1] in [".jpg", ".jpeg", ".JPG", ".JPEG", ".png", ".PNG"]
]
frame_names.sort(key=lambda p: int(os.path.splitext(p)[0]))

# init video predictor state
inference_state = video_predictor.init_state(video_path=video_dir)
step = 20 # the step to sample frames for Grounding DINO predictor

sam2_masks = MaskDictionaryModel()
PROMPT_TYPE_FOR_VIDEO = "mask" # box, mask or point
objects_count = 0
frame_object_count = {}

# å…¨å±€ç‰©ä½“æ ‡ç­¾ä¸€è‡´æ€§ç®¡ç†å™¨
class ObjectLabelConsistencyManager:
    def __init__(self):
        self.object_label_history = {}  # {object_id: [labels_list]}
        self.object_confirmed_labels = {}  # {object_id: confirmed_label}
        self.label_confidence_threshold = 3  # æ ‡ç­¾ç¡®è®¤éœ€è¦çš„æœ€å°æŠ•ç¥¨æ•°
        self.min_consecutive_frames = 5  # æœ€å°è¿ç»­å¸§æ•°è¦æ±‚
        self.object_frame_history = {}  # {object_id: [(frame_idx, label)]}
        
    def add_label_observation(self, object_id, label, confidence=1.0, frame_idx=None):
        """ä¸ºç‰©ä½“æ·»åŠ ä¸€ä¸ªæ ‡ç­¾è§‚å¯Ÿ"""
        if object_id not in self.object_label_history:
            self.object_label_history[object_id] = []
            self.object_frame_history[object_id] = []
        
        # æ·»åŠ å¸¦æƒé‡çš„æ ‡ç­¾è§‚å¯Ÿ
        self.object_label_history[object_id].append((label, confidence))
        
        # è®°å½•å¸§å†å²
        if frame_idx is not None:
            self.object_frame_history[object_id].append((frame_idx, label))
        
        # å¦‚æœè§‚å¯Ÿæ•°é‡è¶³å¤Ÿï¼Œç¡®è®¤æ ‡ç­¾
        if len(self.object_label_history[object_id]) >= self.label_confidence_threshold:
            self._confirm_label(object_id)
    
    def _confirm_label(self, object_id):
        """åŸºäºå†å²è§‚å¯Ÿç¡®è®¤ç‰©ä½“çš„æœ€ç»ˆæ ‡ç­¾"""
        if object_id not in self.object_label_history:
            return
            
        # ç»Ÿè®¡å„æ ‡ç­¾çš„åŠ æƒæŠ•ç¥¨
        label_votes = {}
        for label, confidence in self.object_label_history[object_id]:
            if label not in label_votes:
                label_votes[label] = 0
            label_votes[label] += confidence
        
        # é€‰æ‹©å¾—ç¥¨æœ€é«˜çš„æ ‡ç­¾
        if label_votes:
            confirmed_label = max(label_votes.items(), key=lambda x: x[1])[0]
            
            # æ£€æŸ¥æ ‡ç­¾è¿ç»­æ€§ï¼Œè¿‡æ»¤çŸ­æš‚é”™è¯¯
            if self._is_label_stable(object_id, confirmed_label):
                self.object_confirmed_labels[object_id] = confirmed_label
                print(f"  â†’ ç‰©ä½“ID {object_id} æ ‡ç­¾ç¡®è®¤ä¸º: {confirmed_label}")
            else:
                # å¦‚æœæ ‡ç­¾ä¸ç¨³å®šï¼Œå¯»æ‰¾æœ€ç¨³å®šçš„æ ‡ç­¾
                stable_label = self._find_most_stable_label(object_id)
                if stable_label:
                    self.object_confirmed_labels[object_id] = stable_label
                    print(f"  â†’ ç‰©ä½“ID {object_id} æ ‡ç­¾ä¿®æ­£ä¸ºç¨³å®šæ ‡ç­¾: {stable_label}")
    
    def _is_label_stable(self, object_id, label):
        """æ£€æŸ¥æ ‡ç­¾æ˜¯å¦åœ¨è¶³å¤Ÿå¤šçš„è¿ç»­å¸§ä¸­å‡ºç°"""
        if object_id not in self.object_frame_history:
            return False
        
        frame_history = self.object_frame_history[object_id]
        if len(frame_history) < self.min_consecutive_frames:
            return True  # å¸§æ•°ä¸è¶³ï¼Œæš‚æ—¶è®¤ä¸ºç¨³å®š
        
        # æ£€æŸ¥æœ€è¿‘çš„å¸§ä¸­æ˜¯å¦æœ‰è¶³å¤Ÿçš„è¿ç»­æ€§
        label_sequences = []
        current_sequence = 0
        
        for _, frame_label in frame_history:
            if frame_label == label:
                current_sequence += 1
            else:
                if current_sequence > 0:
                    label_sequences.append(current_sequence)
                current_sequence = 0
        
        if current_sequence > 0:
            label_sequences.append(current_sequence)
        
        # å¦‚æœæœ€é•¿è¿ç»­åºåˆ—å¤§äºç­‰äºæœ€å°è¦æ±‚ï¼Œè®¤ä¸ºç¨³å®š
        max_sequence = max(label_sequences) if label_sequences else 0
        return max_sequence >= self.min_consecutive_frames
    
    def _find_most_stable_label(self, object_id):
        """æ‰¾åˆ°æœ€ç¨³å®šçš„æ ‡ç­¾ï¼ˆè¿ç»­å‡ºç°æœ€å¤šæ¬¡çš„ï¼‰"""
        if object_id not in self.object_frame_history:
            return None
        
        frame_history = self.object_frame_history[object_id]
        label_sequences = {}
        
        for label in set([frame_label for _, frame_label in frame_history]):
            sequences = []
            current_sequence = 0
            
            for _, frame_label in frame_history:
                if frame_label == label:
                    current_sequence += 1
                else:
                    if current_sequence > 0:
                        sequences.append(current_sequence)
                    current_sequence = 0
            
            if current_sequence > 0:
                sequences.append(current_sequence)
            
            max_sequence = max(sequences) if sequences else 0
            label_sequences[label] = max_sequence
        
        # è¿”å›æœ€é•¿è¿ç»­åºåˆ—çš„æ ‡ç­¾
        if label_sequences:
            return max(label_sequences.items(), key=lambda x: x[1])[0]
        return None
    
    def get_consistent_label(self, object_id, current_label=None, frame_idx=None):
        """è·å–ç‰©ä½“çš„ä¸€è‡´æ€§æ ‡ç­¾"""
        # å¦‚æœå·²ç»ç¡®è®¤äº†æ ‡ç­¾ï¼Œç›´æ¥ä½¿ç”¨ç¡®è®¤çš„æ ‡ç­¾
        if object_id in self.object_confirmed_labels:
            return self.object_confirmed_labels[object_id]
        
        # å¦‚æœæœ‰å½“å‰æ£€æµ‹æ ‡ç­¾ï¼Œæ·»åŠ è§‚å¯Ÿ
        if current_label:
            self.add_label_observation(object_id, current_label, frame_idx=frame_idx)
        
        # å¦‚æœè¿˜æ²¡ç¡®è®¤ï¼Œä½¿ç”¨å†å²è§‚å¯Ÿä¸­æœ€é¢‘ç¹çš„æ ‡ç­¾
        if object_id in self.object_label_history and self.object_label_history[object_id]:
            label_counts = {}
            for label, _ in self.object_label_history[object_id]:
                label_counts[label] = label_counts.get(label, 0) + 1
            return max(label_counts.items(), key=lambda x: x[1])[0]
        
        # å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›å½“å‰æ ‡ç­¾
        return current_label
    
    def filter_transient_errors(self, json_data_dir, frame_names):
        """è¿‡æ»¤çŸ­æš‚å‡ºç°çš„é”™è¯¯æ ‡ç­¾"""
        print("\nğŸ” è¿‡æ»¤çŸ­æš‚é”™è¯¯æ ‡ç­¾...")
        
        # é‡æ–°æ”¶é›†æ‰€æœ‰å¸§çš„æ ‡ç­¾ä¿¡æ¯ï¼ŒæŒ‰æ—¶é—´é¡ºåº
        all_objects = {}
        
        for i, frame_name in enumerate(frame_names):
            image_base_name = frame_name.split(".")[0]
            json_path = os.path.join(json_data_dir, f"mask_{image_base_name}.json")
            if os.path.exists(json_path):
                frame_data = MaskDictionaryModel().from_json(json_path)
                for obj_id, obj_info in frame_data.labels.items():
                    if obj_id not in all_objects:
                        all_objects[obj_id] = []
                    all_objects[obj_id].append((i, obj_info.class_name))
        
        # åˆ†ææ¯ä¸ªç‰©ä½“çš„æ ‡ç­¾åºåˆ—ï¼Œè¯†åˆ«å¹¶ä¿®æ­£çŸ­æš‚é”™è¯¯
        corrections_made = {}
        
        for obj_id, label_sequence in all_objects.items():
            if len(label_sequence) < 3:  # å¤ªå°‘çš„è§‚å¯Ÿï¼Œè·³è¿‡
                continue
            
            # æ‰¾åˆ°ä¸»è¦æ ‡ç­¾ï¼ˆå‡ºç°æœ€å¤šçš„ï¼‰
            label_counts = {}
            for _, label in label_sequence:
                label_counts[label] = label_counts.get(label, 0) + 1
            
            if not label_counts:
                continue
                
            main_label = max(label_counts.items(), key=lambda x: x[1])[0]
            
            # å¦‚æœä¸»è¦æ ‡ç­¾å æ¯”è¶³å¤Ÿé«˜ï¼Œä¿®æ­£çŸ­æš‚çš„é”™è¯¯æ ‡ç­¾
            total_frames = len(label_sequence)
            main_label_ratio = label_counts[main_label] / total_frames
            
            if main_label_ratio >= 0.6:  # ä¸»è¦æ ‡ç­¾å 60%ä»¥ä¸Š
                corrections = []
                for frame_idx, label in label_sequence:
                    if label != main_label:
                        corrections.append((frame_idx, label, main_label))
                
                if corrections:
                    corrections_made[obj_id] = {
                        'main_label': main_label,
                        'corrections': corrections
                    }
                    
                    # åº”ç”¨ä¿®æ­£
                    for frame_idx, _, correct_label in corrections:
                        frame_name = frame_names[frame_idx]
                        image_base_name = frame_name.split(".")[0]
                        json_path = os.path.join(json_data_dir, f"mask_{image_base_name}.json")
                        
                        if os.path.exists(json_path):
                            frame_data = MaskDictionaryModel().from_json(json_path)
                            if obj_id in frame_data.labels:
                                frame_data.labels[obj_id].class_name = correct_label
                                frame_data.to_json(json_path)
        
        # è¾“å‡ºä¿®æ­£ç»Ÿè®¡
        if corrections_made:
            print(f"ğŸ“Š çŸ­æš‚é”™è¯¯æ ‡ç­¾ä¿®æ­£ç»Ÿè®¡:")
            for obj_id, correction_info in corrections_made.items():
                main_label = correction_info['main_label']
                corrections = correction_info['corrections']
                print(f"  ç‰©ä½“ID {obj_id}: ä¸»æ ‡ç­¾ '{main_label}' (ä¿®æ­£ {len(corrections)} ä¸ªçŸ­æš‚é”™è¯¯)")
                for frame_idx, wrong_label, _ in corrections[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"    å¸§ {frame_idx}: {wrong_label} â†’ {main_label}")
                if len(corrections) > 3:
                    print(f"    ... è¿˜æœ‰ {len(corrections)-3} ä¸ªä¿®æ­£")
        else:
            print("âœ… æœªå‘ç°éœ€è¦ä¿®æ­£çš„çŸ­æš‚é”™è¯¯æ ‡ç­¾")
    
    def force_label_consistency(self, json_data_dir, frame_names):
        """åœ¨æ•´ä¸ªè§†é¢‘å¤„ç†å®Œæˆåï¼Œå¼ºåˆ¶æ ‡ç­¾ä¸€è‡´æ€§"""
        print("\nğŸ”„ æ‰§è¡Œå…¨å±€æ ‡ç­¾ä¸€è‡´æ€§ä¼˜åŒ–...")
        
        # é¦–å…ˆè¿‡æ»¤çŸ­æš‚é”™è¯¯
        self.filter_transient_errors(json_data_dir, frame_names)
        
        # æ”¶é›†æ‰€æœ‰å¸§çš„æ ‡ç­¾ä¿¡æ¯
        all_frame_labels = {}
        for frame_name in frame_names:
            image_base_name = frame_name.split(".")[0]
            json_path = os.path.join(json_data_dir, f"mask_{image_base_name}.json")
            if os.path.exists(json_path):
                frame_data = MaskDictionaryModel().from_json(json_path)
                for obj_id, obj_info in frame_data.labels.items():
                    if obj_id not in all_frame_labels:
                        all_frame_labels[obj_id] = []
                    all_frame_labels[obj_id].append(obj_info.class_name)
        
        # ä¸ºæ¯ä¸ªç‰©ä½“ç¡®å®šæœ€ä¸€è‡´çš„æ ‡ç­¾
        label_changes = {}
        for obj_id, labels in all_frame_labels.items():
            # ç»Ÿè®¡æ ‡ç­¾é¢‘ç‡
            label_counts = {}
            for label in labels:
                label_counts[label] = label_counts.get(label, 0) + 1
            
            # é€‰æ‹©æœ€é¢‘ç¹çš„æ ‡ç­¾ä½œä¸ºä¸€è‡´æ ‡ç­¾
            if label_counts:
                consistent_label = max(label_counts.items(), key=lambda x: x[1])[0]
                self.object_confirmed_labels[obj_id] = consistent_label
                
                # ç»Ÿè®¡éœ€è¦ä¿®æ”¹çš„æ•°é‡
                changes_needed = sum(1 for label in labels if label != consistent_label)
                if changes_needed > 0:
                    label_changes[obj_id] = {
                        'from_labels': list(set(labels)),
                        'to_label': consistent_label,
                        'changes_count': changes_needed,
                        'total_frames': len(labels)
                    }
        
        # åº”ç”¨æ ‡ç­¾ä¸€è‡´æ€§ä¿®æ­£
        for frame_name in frame_names:
            image_base_name = frame_name.split(".")[0]
            json_path = os.path.join(json_data_dir, f"mask_{image_base_name}.json")
            if os.path.exists(json_path):
                frame_data = MaskDictionaryModel().from_json(json_path)
                modified = False
                
                for obj_id, obj_info in frame_data.labels.items():
                    if obj_id in self.object_confirmed_labels:
                        consistent_label = self.object_confirmed_labels[obj_id]
                        if obj_info.class_name != consistent_label:
                            obj_info.class_name = consistent_label
                            modified = True
                
                if modified:
                    frame_data.to_json(json_path)
        
        # è¾“å‡ºä¿®æ­£ç»Ÿè®¡
        if label_changes:
            print(f"ğŸ“Š æœ€ç»ˆæ ‡ç­¾ä¸€è‡´æ€§ä¿®æ­£ç»Ÿè®¡:")
            for obj_id, change_info in label_changes.items():
                print(f"  ç‰©ä½“ID {obj_id}: {change_info['from_labels']} â†’ {change_info['to_label']} "
                      f"(ä¿®æ­£ {change_info['changes_count']}/{change_info['total_frames']} å¸§)")
        else:
            print("âœ… æ‰€æœ‰ç‰©ä½“æ ‡ç­¾å·²ä¿æŒä¸€è‡´ï¼Œæ— éœ€ä¿®æ­£")

# ç‰©ä½“é‡å æ£€æµ‹å’ŒIDå»é‡ç®¡ç†å™¨
class ObjectOverlapDeduplicationManager:
    def __init__(self):
        self.object_spatial_history = {}  # {object_id: [(frame_idx, bbox, mask_center)]}
        self.overlap_threshold = 0.5  # IoUé˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼è®¤ä¸ºæ˜¯åŒä¸€ç‰©ä½“
        self.mask_overlap_threshold = 0.6  # maské‡å é˜ˆå€¼
        self.center_distance_threshold = 50  # ä¸­å¿ƒç‚¹è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
        self.object_confirmed_labels = {}  # {object_id: confirmed_label}
        
    def calculate_iou(self, box1, box2):
        """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoU"""
        x1 = max(box1[0], box2[0])
        y1 = max(box1[1], box2[1])
        x2 = min(box1[2], box2[2])
        y2 = min(box1[3], box2[3])
        
        if x2 <= x1 or y2 <= y1:
            return 0.0
        
        intersection = (x2 - x1) * (y2 - y1)
        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def calculate_mask_overlap(self, mask1, mask2):
        """è®¡ç®—ä¸¤ä¸ªmaskçš„é‡å æ¯”ä¾‹"""
        if mask1.shape != mask2.shape:
            return 0.0
        
        intersection = (mask1 & mask2).sum()
        union = (mask1 | mask2).sum()
        
        return intersection / union if union > 0 else 0.0
    
    def get_mask_center(self, mask):
        """è·å–maskçš„ä¸­å¿ƒç‚¹"""
        y_coords, x_coords = np.where(mask)
        if len(y_coords) == 0:
            return None
        return (float(np.mean(x_coords)), float(np.mean(y_coords)))
    
    def calculate_center_distance(self, center1, center2):
        """è®¡ç®—ä¸¤ä¸ªä¸­å¿ƒç‚¹çš„è·ç¦»"""
        if center1 is None or center2 is None:
            return float('inf')
        return np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)
    
    def detect_overlapping_objects(self, mask_dict, frame_idx):
        """æ£€æµ‹å½“å‰å¸§ä¸­é‡å çš„ç‰©ä½“å¹¶å»é‡"""
        if len(mask_dict.labels) <= 1:
            return mask_dict
        
        print(f"\nğŸ” æ£€æµ‹å¸§ {frame_idx} ä¸­çš„é‡å ç‰©ä½“...")
        
        # æ”¶é›†æ‰€æœ‰ç‰©ä½“çš„ç©ºé—´ä¿¡æ¯
        objects_info = []
        for obj_id, obj_info in mask_dict.labels.items():
            bbox = obj_info.bbox if hasattr(obj_info, 'bbox') and obj_info.bbox is not None else [0, 0, 0, 0]
            mask_center = self.get_mask_center(obj_info.mask)
            objects_info.append({
                'id': obj_id,
                'info': obj_info,
                'bbox': bbox,
                'center': mask_center,
                'label': obj_info.class_name
            })
        
        # æ£€æµ‹é‡å ç‰©ä½“å¯¹
        overlapping_pairs = []
        for i in range(len(objects_info)):
            for j in range(i + 1, len(objects_info)):
                obj1, obj2 = objects_info[i], objects_info[j]
                
                # è®¡ç®—IoU
                iou = self.calculate_iou(obj1['bbox'], obj2['bbox'])
                
                # è®¡ç®—maské‡å 
                mask_overlap = self.calculate_mask_overlap(obj1['info'].mask, obj2['info'].mask)
                
                # è®¡ç®—ä¸­å¿ƒè·ç¦»
                center_dist = self.calculate_center_distance(obj1['center'], obj2['center'])
                
                # åˆ¤æ–­æ˜¯å¦é‡å ï¼ˆä»»ä¸€æ¡ä»¶æ»¡è¶³ï¼‰
                is_overlapping = (
                    iou > self.overlap_threshold or 
                    mask_overlap > self.mask_overlap_threshold or
                    center_dist < self.center_distance_threshold
                )
                
                if is_overlapping:
                    overlapping_pairs.append({
                        'obj1': obj1,
                        'obj2': obj2,
                        'iou': iou,
                        'mask_overlap': mask_overlap,
                        'center_distance': center_dist
                    })
                    print(f"  å‘ç°é‡å ç‰©ä½“: ID{obj1['id']}({obj1['label']}) â†” ID{obj2['id']}({obj2['label']}) "
                          f"[IoU:{iou:.3f}, Maské‡å :{mask_overlap:.3f}, ä¸­å¿ƒè·ç¦»:{center_dist:.1f}]")
        
        if not overlapping_pairs:
            print("  âœ… æœªå‘ç°é‡å ç‰©ä½“")
            return mask_dict
        
        # å»é‡ï¼šä¿ç•™æœ€ä½³ç‰©ä½“
        objects_to_remove = set()
        deduplication_log = []
        
        for pair in overlapping_pairs:
            obj1, obj2 = pair['obj1'], pair['obj2']
            
            # å¦‚æœå…¶ä¸­ä¸€ä¸ªå·²ç»è¢«æ ‡è®°åˆ é™¤ï¼Œè·³è¿‡
            if obj1['id'] in objects_to_remove or obj2['id'] in objects_to_remove:
                continue
            
            # å†³ç­–é€»è¾‘ï¼šä¼˜å…ˆä¿ç•™æ›´å‡†ç¡®çš„æ ‡ç­¾å’Œæ›´å¤§çš„mask
            keep_obj1 = self._decide_which_object_to_keep(obj1, obj2, pair)
            
            if keep_obj1:
                objects_to_remove.add(obj2['id'])
                deduplication_log.append(f"ä¿ç•™ID{obj1['id']}({obj1['label']}), ç§»é™¤ID{obj2['id']}({obj2['label']})")
            else:
                objects_to_remove.add(obj1['id'])
                deduplication_log.append(f"ä¿ç•™ID{obj2['id']}({obj2['label']}), ç§»é™¤ID{obj1['id']}({obj1['label']})")
        
        # æ‰§è¡Œå»é‡
        if objects_to_remove:
            print(f"  ğŸ—‘ï¸  å»é‡æ“ä½œ:")
            for log in deduplication_log:
                print(f"    {log}")
            
            # åˆ›å»ºå»é‡åçš„mask_dict
            deduplicated_mask_dict = MaskDictionaryModel(
                promote_type=mask_dict.promote_type,
                mask_name=mask_dict.mask_name
            )
            
            for obj_id, obj_info in mask_dict.labels.items():
                if obj_id not in objects_to_remove:
                    deduplicated_mask_dict.labels[obj_id] = obj_info
            
            print(f"  ğŸ“Š å»é‡ç»“æœ: {len(mask_dict.labels)} â†’ {len(deduplicated_mask_dict.labels)} ä¸ªç‰©ä½“")
            return deduplicated_mask_dict
        
        return mask_dict
    
    def _decide_which_object_to_keep(self, obj1, obj2, overlap_info):
        """å†³å®šä¿ç•™å“ªä¸ªç‰©ä½“çš„é€»è¾‘ - é’ˆå¯¹holeä¼˜åŒ–"""
        # 1. ä¼˜å…ˆçº§ï¼šhole > å…¶ä»–ç‰©ä½“ï¼ˆholeæ˜¯æˆ‘ä»¬çš„ä¸»è¦ç›®æ ‡ï¼‰
        label_priority = {'hole': 3, 'mouse': 2, 'bag': 1}
        priority1 = label_priority.get(obj1['label'], 0)
        priority2 = label_priority.get(obj2['label'], 0)
        
        if priority1 != priority2:
            return priority1 > priority2
        
        # 2. å¦‚æœéƒ½æ˜¯holeï¼Œä¿ç•™æ›´ç¬¦åˆholeç‰¹å¾çš„ï¼ˆæ›´åœ†ã€æ›´ç´§å‡‘çš„ï¼‰
        if obj1['label'] == 'hole' and obj2['label'] == 'hole':
            # è®¡ç®—å½¢çŠ¶ç´§å‡‘åº¦
            area1 = obj1['info'].mask.sum()
            area2 = obj2['info'].mask.sum()
            bbox1 = obj1['bbox']
            bbox2 = obj2['bbox']
            
            # è®¡ç®—ç´§å‡‘åº¦
            bbox_area1 = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])
            bbox_area2 = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])
            
            compactness1 = area1 / bbox_area1 if bbox_area1 > 0 else 0
            compactness2 = area2 / bbox_area2 if bbox_area2 > 0 else 0
            
            # ä¿ç•™æ›´ç´§å‡‘çš„hole
            if abs(compactness1 - compactness2) > 0.1:
                return compactness1 > compactness2
        
        # 3. å¦‚æœæ ‡ç­¾ä¼˜å…ˆçº§ç›¸åŒï¼Œæ¯”è¾ƒmaské¢ç§¯ï¼ˆä¿ç•™æ›´å¤§çš„ï¼‰
        area1 = obj1['info'].mask.sum()
        area2 = obj2['info'].mask.sum()
        
        if abs(area1 - area2) > min(area1, area2) * 0.3:  # é¢ç§¯å·®å¼‚è¶…è¿‡30%
            return area1 > area2
        
        # 4. å¦‚æœé¢ç§¯ç›¸è¿‘ï¼Œä¿ç•™IDè¾ƒå°çš„ï¼ˆé€šå¸¸æ˜¯å…ˆæ£€æµ‹åˆ°çš„ï¼‰
        return obj1['id'] < obj2['id']
    
    def update_spatial_history(self, object_id, frame_idx, bbox, mask):
        """æ›´æ–°ç‰©ä½“çš„ç©ºé—´å†å²"""
        if object_id not in self.object_spatial_history:
            self.object_spatial_history[object_id] = []
        
        mask_center = self.get_mask_center(mask)
        self.object_spatial_history[object_id].append((frame_idx, bbox, mask_center))
        
        # åªä¿ç•™æœ€è¿‘çš„å†å²è®°å½•ï¼ˆé¿å…å†…å­˜è¿‡å¤§ï¼‰
        max_history = 50
        if len(self.object_spatial_history[object_id]) > max_history:
            self.object_spatial_history[object_id] = self.object_spatial_history[object_id][-max_history:]

# åˆå§‹åŒ–ç®¡ç†å™¨
label_manager = ObjectLabelConsistencyManager()
overlap_manager = ObjectOverlapDeduplicationManager()
tracking_history = TrackingHistoryManager(
    max_missing_frames=5,      # å…è®¸ç‰©ä½“ç¼ºå¤±5å¸§åå†åˆ é™¤
    max_movement_ratio=0.2,    # æœ€å¤§ç§»åŠ¨è·ç¦»ä¸è¶…è¿‡å›¾åƒå¯¹è§’çº¿çš„20%
    max_size_change_ratio=0.6  # æœ€å¤§å°ºå¯¸å˜åŒ–ä¸è¶…è¿‡60%
)

"""
Step 2: Prompt Grounding DINO and SAM image predictor to get the box and mask for all frames
"""
print("è§†é¢‘æ€»å¸§æ•°:", len(frame_names))
for start_frame_idx in range(0, len(frame_names), step):
# prompt grounding dino to get the box coordinates on specific frame
    # continue
    img_path = os.path.join(video_dir, frame_names[start_frame_idx])
    image = Image.open(img_path).convert("RGB")
    image_base_name = frame_names[start_frame_idx].split(".")[0]
    mask_dict = MaskDictionaryModel(promote_type = PROMPT_TYPE_FOR_VIDEO, mask_name = f"mask_{image_base_name}.npy")

    # ä½¿ç”¨æœ¬åœ° GroundingDINO è¿›è¡Œæ¨ç†
    image_source, transformed_image = load_image(img_path)
    
    # åœ¨ float32 ç²¾åº¦ä¸‹è¿›è¡Œæ¨ç†ï¼Œæé«˜holeæ£€æµ‹çš„ç²¾åº¦
    with torch.autocast(device_type="cuda", dtype=torch.float32):
        boxes, confidences, labels = predict(
            model=grounding_model, 
            image=transformed_image, 
            caption=text, 
            box_threshold=0.41314,  # å¤§å¹…é™ä½boxé˜ˆå€¼ä»¥æ£€æµ‹æ›´å¤šholeå€™é€‰
            text_threshold=0.31314,  # å¤§å¹…é™ä½texté˜ˆå€¼æé«˜å¬å›ç‡
            device=device
        )
    
    # è½¬æ¢åæ ‡æ ¼å¼å’Œæ•°æ®ç±»å‹
    if len(boxes) > 0:
        # è½¬æ¢ä¸ºnumpyæ ¼å¼å¹¶ç¡®ä¿å¯å†™
        input_boxes = boxes.cpu().numpy().copy()
        confidences = confidences.cpu().numpy().copy()
        
        # è·å–å›¾åƒå°ºå¯¸
        H, W = image_source.shape[:2]
        
        # è½¬æ¢è¾¹ç•Œæ¡†åæ ‡åˆ°åƒç´ åæ ‡ (ä»å½’ä¸€åŒ–åæ ‡åˆ°åƒç´ åæ ‡)
        input_boxes[:, [0, 2]] *= W  # xåæ ‡
        input_boxes[:, [1, 3]] *= H  # yåæ ‡
        
        # GroundingDINOè¿”å›çš„æ˜¯(cx, cy, w, h)æ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸º(x1, y1, x2, y2)
    if len(boxes) > 0:
        # è½¬æ¢ä¸ºnumpyæ ¼å¼å¹¶ç¡®ä¿å¯å†™
        if hasattr(boxes, 'cpu'):
            input_boxes = boxes.cpu().numpy().copy()
        else:
            input_boxes = np.array(boxes).copy()
        if hasattr(confidences, 'cpu'):
            confidences_np = confidences.cpu().numpy().copy()
        else:
            confidences_np = np.array(confidences).copy()

        # è·å–å›¾åƒå°ºå¯¸
        H, W = image_source.shape[:2]

        # è½¬æ¢è¾¹ç•Œæ¡†åæ ‡åˆ°åƒç´ åæ ‡ (ä»å½’ä¸€åŒ–åæ ‡åˆ°åƒç´ åæ ‡)
        input_boxes[:, [0, 2]] *= W  # xåæ ‡
        input_boxes[:, [1, 3]] *= H  # yåæ ‡

        # GroundingDINOè¿”å›çš„æ˜¯(cx, cy, w, h)æ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸º(x1, y1, x2, y2)
        boxes_xyxy = input_boxes.copy()
        boxes_xyxy[:, 0] = input_boxes[:, 0] - input_boxes[:, 2] / 2  # x1 = cx - w/2
        boxes_xyxy[:, 1] = input_boxes[:, 1] - input_boxes[:, 3] / 2  # y1 = cy - h/2
        boxes_xyxy[:, 2] = input_boxes[:, 0] + input_boxes[:, 2] / 2  # x2 = cx + w/2
        boxes_xyxy[:, 3] = input_boxes[:, 1] + input_boxes[:, 3] / 2  # y2 = cy + h/2

        input_boxes = boxes_xyxy

        # è¿‡æ»¤å’ŒéªŒè¯æ£€æµ‹åˆ°çš„ç‰©ä½“ï¼ˆä¸“é—¨é’ˆå¯¹holeä¼˜åŒ–ï¼‰
        # è®¡ç®—å›¾åƒé¢ç§¯
        image_area = H * W
        valid_indices = []
        filtered_boxes = []
        filtered_confidences = []
        filtered_labels = []
        validation_results = []

        print(f"ğŸ” å¼€å§‹éªŒè¯ {len(input_boxes)} ä¸ªæ£€æµ‹å€™é€‰:")
        
        for i, box in enumerate(input_boxes):
            x1, y1, x2, y2 = box
            box_width = x2 - x1
            box_height = y2 - y1
            box_area = box_width * box_height
            area_ratio = box_area / image_area

            # æ¸…ç†æ ‡ç­¾ï¼Œå»é™¤å¤šä½™ç©ºæ ¼å¹¶è½¬ä¸ºå°å†™
            clean_label = labels[i].strip().lower()
            if ' ' in clean_label:
                clean_label = clean_label.split()[0]  # å–ç¬¬ä¸€ä¸ªè¯ä½œä¸ºä¸»æ ‡ç­¾
            
            # 1. åŸºç¡€å°ºå¯¸è¿‡æ»¤ï¼ˆæ›´å®½æ¾çš„åˆæ­¥è¿‡æ»¤ï¼‰
            basic_size_ok = (
                area_ratio < 0.8 and  # ä¸èƒ½å æ®å›¾åƒ80%ä»¥ä¸Š
                box_width < W * 0.95 and 
                box_height < H * 0.95 and
                box_width > 5 and   # æœ€å°5åƒç´ 
                box_height > 5      # æœ€å°5åƒç´ 
            )
            
            if not basic_size_ok:
                print(f"    âŒ å€™é€‰ {i+1}: {clean_label} - å°ºå¯¸ä¸åˆç† (é¢ç§¯æ¯”: {area_ratio:.3f}, å°ºå¯¸: {box_width:.0f}x{box_height:.0f})")
                continue
            
            # 2. æ ‡ç­¾ç›¸å…³æ€§æ£€éªŒï¼ˆå¢å¼ºç‰ˆï¼šå¼ºè°ƒæ·±åº¦ç‰¹å¾ï¼‰
            hole_related_terms = ['hole', 'opening', 'circular', 'round', 'gap', 'deep', 'dark', 'shadow', 'cavity', 'depth']
            depth_related_terms = ['deep', 'dark', 'shadow', 'cavity', 'depth']
            
            is_hole_related = any(term in clean_label for term in hole_related_terms)
            has_depth_hint = any(term in clean_label for term in depth_related_terms)
            
            # å¦‚æœæ ‡ç­¾åŒ…å«æ·±åº¦ç›¸å…³è¯æ±‡ï¼Œç»™äºˆæ›´é«˜ä¼˜å…ˆçº§
            if has_depth_hint:
                print(f"    âœ“ å€™é€‰ {i+1}: {clean_label} - åŒ…å«æ·±åº¦ç‰¹å¾è¯æ±‡ï¼Œä¼˜å…ˆçº§æå‡")
            elif not is_hole_related:
                print(f"    âŒ å€™é€‰ {i+1}: {clean_label} - æ ‡ç­¾ä¸holeæ— å…³")
                continue
            
            print(f"    âœ“ å€™é€‰ {i+1}: {clean_label} - é€šè¿‡åˆæ­¥éªŒè¯ (ç½®ä¿¡åº¦: {confidences_np[i]:.3f})")
            
            # æš‚æ—¶æ·»åŠ åˆ°æœ‰æ•ˆåˆ—è¡¨ï¼Œåç»­è¿›è¡Œæ›´è¯¦ç»†çš„éªŒè¯
            valid_indices.append(i)
            filtered_boxes.append(box)
            filtered_confidences.append(confidences_np[i])
            filtered_labels.append('hole')  # ç»Ÿä¸€æ ‡è®°ä¸ºhole
            
        print(f"ğŸ“Š åˆæ­¥è¿‡æ»¤ç»“æœ: {len(input_boxes)} â†’ {len(valid_indices)} ä¸ªå€™é€‰")

        if len(valid_indices) > 0:
            input_boxes = np.array(filtered_boxes)
            confidences = np.array(filtered_confidences)
            OBJECTS = filtered_labels
        else:
            input_boxes = np.empty((0, 4))
            confidences = np.array([])
            OBJECTS = []
            print("è¿‡æ»¤åæœªå‘ç°æœ‰æ•ˆå¯¹è±¡")
    else:
        input_boxes = np.empty((0, 4))
        OBJECTS = []
        print("æœªæ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡")


    # ========== ç‰©ä½“é‡å æ£€æµ‹å’ŒIDå»é‡ï¼ˆåœ¨åˆ†å‰²å‰ï¼ŒåŸºäºæ£€æµ‹æ¡†å’Œæ ‡ç­¾ï¼‰ ==========
    if len(input_boxes) > 1:
        # æ„é€ ä¸€ä¸ªä¸´æ—¶mask_dictç”¨äºå»é‡ï¼ˆåªç”¨boxå’Œlabelï¼‰
        temp_mask_dict = MaskDictionaryModel(promote_type=mask_dict.promote_type, mask_name=mask_dict.mask_name)
        for i, box in enumerate(input_boxes):
            # ä¼ªé€ ä¸€ä¸ªObjectInfoï¼Œä»…ç”¨boxå’Œlabel
            temp_obj = ObjectInfo(instance_id=i+1, mask=np.zeros((int(H), int(W)), dtype=bool), class_name=OBJECTS[i], logit=None)
            temp_obj.bbox = box
            temp_mask_dict.labels[i+1] = temp_obj
        # å»é‡
        deduped_mask_dict = overlap_manager.detect_overlapping_objects(temp_mask_dict, start_frame_idx)
        # åªä¿ç•™æœªè¢«å»é‡çš„boxå’Œlabel
        keep_indices = []
        for obj_id, obj_info in deduped_mask_dict.labels.items():
            # æ‰¾åˆ°åŸå§‹index
            for i, box in enumerate(input_boxes):
                if np.allclose(box, obj_info.bbox, atol=1.0) and OBJECTS[i] == obj_info.class_name:
                    keep_indices.append(i)
                    break
        if keep_indices:
            input_boxes = input_boxes[keep_indices]
            confidences = confidences[keep_indices]
            OBJECTS = [OBJECTS[i] for i in keep_indices]
            print(f"å»é‡åä¿ç•™ {len(OBJECTS)} ä¸ªå¯¹è±¡: {OBJECTS}")
        else:
            input_boxes = np.empty((0, 4))
            confidences = np.array([])
            OBJECTS = []
            print("å»é‡åæœªä¿ç•™ä»»ä½•å¯¹è±¡")

    # prompt SAM image predictor to get the mask for the object
    image_predictor.set_image(np.array(image.convert("RGB")))
    if input_boxes.shape[0] != 0:
        # prompt SAM 2 image predictor to get the mask for the object
        masks, scores, logits = image_predictor.predict(
            point_coords=None,
            point_labels=None,
            box=input_boxes,
            multimask_output=False,
        )
        # convert the mask shape to (n, H, W)
        if masks.ndim == 2:
            masks = masks[None]
            scores = scores[None]
            logits = logits[None]
        elif masks.ndim == 4:
            masks = masks.squeeze(1)
        
        # ğŸ”§ ç¡®ä¿ç”Ÿæˆçš„maskså°ºå¯¸ä¸å›¾åƒå°ºå¯¸åŒ¹é…
        if masks.shape[1:] != (H, W):
            print(f"    âš ï¸  è°ƒæ•´SAM2ç”Ÿæˆçš„maskså°ºå¯¸: {masks.shape} â†’ (n, {H}, {W})")
            adjusted_masks = []
            for i in range(masks.shape[0]):
                mask = masks[i]
                if mask.shape != (H, W):
                    # ä½¿ç”¨æœ€è¿‘é‚»æ’å€¼è°ƒæ•´maskå°ºå¯¸
                    mask_resized = cv2.resize(mask.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)
                    adjusted_masks.append(mask_resized)
                else:
                    adjusted_masks.append(mask)
            masks = np.array(adjusted_masks)
        
        # ğŸ” é‡è¦ï¼šæ·»åŠ holeç‰¹å¾éªŒè¯é˜¶æ®µ
        print(f"\nğŸ”¬ å¼€å§‹è¯¦ç»†holeç‰¹å¾éªŒè¯:")
        validated_masks = []
        validated_boxes = []
        validated_labels = []
        validated_confidences = []
        
        for i in range(len(masks)):
            mask = masks[i]
            box = input_boxes[i]
            confidence = confidences[i]
            label = OBJECTS[i]
            
            # éªŒè¯holeç‰¹å¾ï¼ˆä¼ å…¥åŸå§‹å›¾åƒè¿›è¡Œæ·±åº¦åˆ†æï¼‰
            image_array = np.array(image.convert("RGB"))
            is_valid_hole, hole_score, validation_info = validate_hole_features(
                mask, box, (H, W), confidence, image_array
            )
            
            print(f"  ğŸ” éªŒè¯å€™é€‰ {i+1}: {label}")
            print(f"    - é¢ç§¯æ¯”ä¾‹: {validation_info['area_ratio']:.6f}")
            print(f"    - å½¢çŠ¶ç´§å‡‘åº¦: {validation_info['compactness']:.3f}")
            print(f"    - å®½é«˜æ¯”: {validation_info['aspect_ratio']:.3f}")
            print(f"    - è¾¹ç¼˜è·ç¦»: {validation_info['edge_distance_ratio']:.3f}")
            print(f"    - æ·±åº¦ç‰¹å¾: {validation_info['depth_score']:.3f}")
            print(f"    - çº¹ç†ç‰¹å¾: {validation_info['texture_score']:.3f}")
            print(f"    - è¾¹ç¼˜æ¢¯åº¦: {validation_info['edge_gradient_score']:.3f}")
            print(f"    - åœ†åº¦ç‰¹å¾: {validation_info['circularity_score']:.3f}")
            print(f"    - ğŸ†•äº®åº¦å¯¹æ¯”: {validation_info['brightness_score']:.3f}")
            print(f"    - ğŸ†•å¯¹æ¯”åº¦: {validation_info['contrast_score']:.3f}")
            print(f"    - ç»¼åˆè¯„åˆ†: {hole_score:.3f}/{validation_info['threshold']}")
            
            if is_valid_hole:
                # é¢å¤–éªŒè¯ï¼šæ·±åº¦ã€çº¹ç†å’Œäº®åº¦åˆ†æ•°éƒ½å¿…é¡»è¾¾åˆ°æœ€ä½æ ‡å‡†
                depth_ok = validation_info['depth_score'] >= 0.11314  # æ·±åº¦ç‰¹å¾å¿…é¡»æ˜æ˜¾
                texture_ok = validation_info['texture_score'] >= 0.11314  # çº¹ç†å¿…é¡»ç›¸å¯¹å‡åŒ€
                brightness_ok = validation_info['brightness_score'] >= 0.01314  # ğŸ†• äº®åº¦å¯¹æ¯”å¿…é¡»æ˜æ˜¾ï¼ˆå…³é”®ï¼ï¼‰
                
                if depth_ok and texture_ok and brightness_ok:
                    print(f"    âœ… éªŒè¯é€šè¿‡ - ç¡®è®¤ä¸ºæœ‰æ•ˆholeï¼ˆæ·±åº¦+çº¹ç†+äº®åº¦éªŒè¯é€šè¿‡ï¼‰")
                    validated_masks.append(mask)
                    validated_boxes.append(box)
                    validated_labels.append('hole')
                    validated_confidences.append(hole_score)  # ä½¿ç”¨éªŒè¯åçš„ç½®ä¿¡åº¦
                elif not depth_ok:
                    print(f"    âŒ éªŒè¯å¤±è´¥ - æ·±åº¦ç‰¹å¾ä¸è¶³ï¼ˆ{validation_info['depth_score']:.3f} < 0.11314ï¼‰ï¼Œå¯èƒ½æ˜¯å¹³é¢ç‰©ä½“")
                elif not texture_ok:
                    print(f"    âŒ éªŒè¯å¤±è´¥ - çº¹ç†è¿‡äºå¤æ‚ï¼ˆ{validation_info['texture_score']:.3f} < 0.11314ï¼‰ï¼Œå¯èƒ½æ˜¯æœ¨æ¿ç­‰å¹³é¢ç‰©ä½“")
                elif not brightness_ok:
                    print(f"    âŒ éªŒè¯å¤±è´¥ - äº®åº¦å¯¹æ¯”ä¸è¶³ï¼ˆ{validation_info['brightness_score']:.3f} < 0.01314ï¼‰ï¼Œå¯èƒ½æ˜¯æµ…è‰²å¹³é¢ç‰©ä½“å¦‚æœ¨æ¿")
            else:
                print(f"    âŒ éªŒè¯å¤±è´¥ - ç»¼åˆè¯„åˆ†ä¸è¶³")
                # åˆ†æä¸»è¦å¤±è´¥åŸå› 
                if validation_info['depth_score'] < 0.4:
                    print(f"      ä¸»è¦åŸå› ï¼šç¼ºä¹æ·±åº¦ç‰¹å¾ï¼ˆäº®åº¦å·®å¼‚ä¸è¶³ï¼‰")
                if validation_info['brightness_score'] < 0.4:
                    print(f"      ä¸»è¦åŸå› ï¼šäº®åº¦å¯¹æ¯”ä¸è¶³ï¼ˆå¯èƒ½æ˜¯å¹³é¢ç‰©ä½“å¦‚æœ¨æ¿ï¼‰")
                if validation_info['texture_score'] < 0.4:
                    print(f"      ä¸»è¦åŸå› ï¼šçº¹ç†è¿‡äºå¤æ‚ï¼ˆä¸åƒholeå†…éƒ¨ï¼‰")
                if validation_info['compactness'] < 0.5:
                    print(f"      ä¸»è¦åŸå› ï¼šå½¢çŠ¶ä¸å¤Ÿç´§å‡‘")
                if validation_info['circularity_score'] < 0.4:
                    print(f"      ä¸»è¦åŸå› ï¼šå½¢çŠ¶ä¸å¤Ÿåœ†å½¢")
        
        print(f"ğŸ“Š æœ€ç»ˆéªŒè¯ç»“æœ: {len(masks)} â†’ {len(validated_masks)} ä¸ªç¡®è®¤hole")
        
        if len(validated_masks) > 0:
            # ä½¿ç”¨éªŒè¯åçš„ç»“æœ
            masks = np.array(validated_masks)
            input_boxes = np.array(validated_boxes)
            OBJECTS = validated_labels
            confidences = np.array(validated_confidences)
            
            print(f"âœ… æœ€ç»ˆç¡®è®¤çš„hole:")
            for i, (conf, label) in enumerate(zip(confidences, OBJECTS)):
                print(f"  Hole {i+1}: {label} (éªŒè¯è¯„åˆ†: {conf:.3f})")
        else:
            # æ²¡æœ‰éªŒè¯é€šè¿‡çš„hole
            masks = np.empty((0, H, W))
            input_boxes = np.empty((0, 4))
            OBJECTS = []
            confidences = np.array([])
            print("âŒ æœªå‘ç°ç¬¦åˆç‰¹å¾çš„hole")
        
        # Step 3: Register each object's positive points to video predictor
        if len(OBJECTS) > 0 and mask_dict.promote_type == "mask":
            mask_dict.add_new_frame_annotation(mask_list=torch.tensor(masks).to(device), box_list=torch.tensor(input_boxes), label_list=OBJECTS)
        else:
            if len(OBJECTS) == 0:
                pass  # Skip silently
            else:
                raise NotImplementedError("SAM 2 video predictor only support mask prompts")
    else:
        mask_dict = sam2_masks

    """
    Step 4: Propagate the video predictor to get the segmentation results for each frame
    """
    # ä¼˜åŒ–çš„è¿½è¸ªæ›´æ–°ï¼šä½¿ç”¨æ›´å®½æ¾çš„IoUé˜ˆå€¼å’Œå¤šé‡åŒ¹é…ç­–ç•¥
    objects_count = mask_dict.update_masks_enhanced(
        tracking_annotation_dict=sam2_masks, 
        iou_threshold=0.5,  # è¿›ä¸€æ­¥é™ä½IoUé˜ˆå€¼ï¼Œæé«˜è¿½è¸ªè¿ç»­æ€§
        spatial_threshold=80,  # å¢åŠ ç©ºé—´è·ç¦»é˜ˆå€¼ï¼Œå…è®¸æ›´å¤§çš„ç§»åŠ¨
        objects_count=objects_count,
        tracking_history=tracking_history  # ä¼ å…¥è¿½è¸ªå†å²ç®¡ç†å™¨
    )
    
    # ä¸ºæ–°æ£€æµ‹åˆ°çš„ç‰©ä½“æ·»åŠ æ ‡ç­¾è§‚å¯Ÿåˆ°ä¸€è‡´æ€§ç®¡ç†å™¨å’Œåˆç†æ€§æ£€æŸ¥
    valid_objects = {}
    image_shape = (H, W)  # ä½¿ç”¨å½“å‰å¸§çš„å›¾åƒå°ºå¯¸
    
    for object_id, object_info in mask_dict.labels.items():
        current_label = object_info.class_name
        
        # è®¡ç®—ç‰©ä½“ä¸­å¿ƒå’Œé¢ç§¯
        mask_center = tracking_history._get_mask_center(object_info.mask)
        mask_area = object_info.mask.sum().item() if isinstance(object_info.mask, torch.Tensor) else object_info.mask.sum()
        
        # è¿åŠ¨å’Œå°ºå¯¸åˆç†æ€§æ£€æŸ¥
        is_consistent = tracking_history.validate_object_consistency(
            object_id, mask_center, mask_area, image_shape
        )
        
        if is_consistent:
            # æ·»åŠ å½“å‰æ£€æµ‹çš„æ ‡ç­¾è§‚å¯Ÿï¼ˆæ–°æ£€æµ‹çš„æ ‡ç­¾æƒé‡æ›´é«˜ï¼‰
            label_manager.add_label_observation(object_id, current_label, confidence=2.0, frame_idx=start_frame_idx)
            # è·å–ä¸€è‡´æ€§æ ‡ç­¾å¹¶æ›´æ–°
            consistent_label = label_manager.get_consistent_label(object_id, current_label, frame_idx=start_frame_idx)
            if consistent_label != current_label:
                print(f"  ğŸ“ æ ‡ç­¾ä¸€è‡´æ€§ä¿®æ­£: ç‰©ä½“ID {object_id} {current_label} â†’ {consistent_label}")
                object_info.class_name = consistent_label
            
            # æ›´æ–°è¿½è¸ªå†å²
            tracking_history.update_object_position(object_id, mask_center, start_frame_idx, mask_area)
            valid_objects[object_id] = object_info
        else:
            print(f"  ğŸš« è¿‡æ»¤ç‰©ä½“ID {object_id}ï¼šè¿åŠ¨æˆ–å°ºå¯¸å˜åŒ–ä¸åˆç†")
    
    # æ›´æ–°mask_dictåªä¿ç•™åˆç†çš„ç‰©ä½“
    mask_dict.labels = valid_objects
    
    # ğŸ” è¿½è¸ªè´¨é‡ç›‘æ§
    print(f"\nğŸ“Š å¸§ {start_frame_idx} è¿½è¸ªè´¨é‡æŠ¥å‘Š:")
    print(f"  å½“å‰è¿½è¸ªç‰©ä½“æ•°é‡: {len(mask_dict.labels)}")
    print(f"  å†å²è¿½è¸ªè®°å½•: {len(tracking_history.object_history)} ä¸ªç‰©ä½“")
    
    # æ˜¾ç¤ºæ¯ä¸ªç‰©ä½“çš„è¿½è¸ªçŠ¶æ€
    for object_id, object_info in mask_dict.labels.items():
        if object_id in tracking_history.object_history:
            history = tracking_history.object_history[object_id]
            missing_count = history['missing_count']
            position_count = len(history['positions'])
            if missing_count > 0:
                print(f"    ğŸŸ¡ ID {object_id} ({object_info.class_name}): è¿ç»­ç¼ºå¤± {missing_count} å¸§ï¼Œå†å²ä½ç½® {position_count} ä¸ª")
            else:
                print(f"    ğŸŸ¢ ID {object_id} ({object_info.class_name}): æ­£å¸¸è¿½è¸ªï¼Œå†å²ä½ç½® {position_count} ä¸ª")
        else:
            print(f"    ğŸ”µ ID {object_id} ({object_info.class_name}): æ–°æ£€æµ‹ç‰©ä½“")
    
    frame_object_count[start_frame_idx] = objects_count
    print(f"ç´¯è®¡ç‰©ä½“è®¡æ•°: {objects_count}")
    
    if len(mask_dict.labels) == 0:
        mask_dict.save_empty_mask_and_json(mask_data_dir, json_data_dir, image_name_list = frame_names[start_frame_idx:start_frame_idx+step])
        continue
    else:
        video_predictor.reset_state(inference_state)

        for object_id, object_info in mask_dict.labels.items():
            frame_idx, out_obj_ids, out_mask_logits = video_predictor.add_new_mask(
                    inference_state,
                    start_frame_idx,
                    object_id,
                    object_info.mask,
                )
        
        video_segments = {}  # output the following {step} frames tracking masks
        for out_frame_idx, out_obj_ids, out_mask_logits in video_predictor.propagate_in_video(inference_state, max_frame_num_to_track=step, start_frame_idx=start_frame_idx):
            frame_masks = MaskDictionaryModel()
            
            for i, out_obj_id in enumerate(out_obj_ids):
                out_mask = (out_mask_logits[i] > 0.0) # .cpu().numpy()
                
                # è·å–ä¸€è‡´æ€§æ ‡ç­¾
                original_class_name = mask_dict.get_target_class_name(out_obj_id)
                consistent_class_name = label_manager.get_consistent_label(out_obj_id, original_class_name, frame_idx=out_frame_idx)
                
                object_info = ObjectInfo(
                    instance_id=out_obj_id, 
                    mask=out_mask[0], 
                    class_name=consistent_class_name,  # ä½¿ç”¨ä¸€è‡´æ€§æ ‡ç­¾
                    logit=mask_dict.get_target_logit(out_obj_id)
                )
                object_info.update_box()
                
                # è¿åŠ¨å’Œå°ºå¯¸åˆç†æ€§æ£€æŸ¥
                mask_center = tracking_history._get_mask_center(out_mask[0])
                mask_area = out_mask[0].sum().item() if isinstance(out_mask[0], torch.Tensor) else out_mask[0].sum()
                
                # éªŒè¯ç‰©ä½“è¿åŠ¨å’Œå°ºå¯¸å˜åŒ–çš„åˆç†æ€§
                image_shape = (out_mask.shape[-2], out_mask.shape[-1])
                is_consistent = tracking_history.validate_object_consistency(
                    out_obj_id, mask_center, mask_area, image_shape
                )
                
                if is_consistent:
                    # åªæœ‰é€šè¿‡åˆç†æ€§æ£€æŸ¥çš„ç‰©ä½“æ‰ä¼šè¢«ä¿ç•™
                    frame_masks.labels[out_obj_id] = object_info
                    # æ›´æ–°è¿½è¸ªå†å²
                    tracking_history.update_object_position(out_obj_id, mask_center, out_frame_idx, mask_area)
                else:
                    # ä¸åˆç†çš„æ£€æµ‹ï¼Œè·³è¿‡è¿™ä¸ªç‰©ä½“
                    print(f"    ğŸš« è·³è¿‡ç‰©ä½“ID {out_obj_id}ï¼šè¿åŠ¨æˆ–å°ºå¯¸å˜åŒ–ä¸åˆç†")
                    continue
                
                image_base_name = frame_names[out_frame_idx].split(".")[0]
                frame_masks.mask_name = f"mask_{image_base_name}.npy"
                frame_masks.mask_height = out_mask.shape[-2]
                frame_masks.mask_width = out_mask.shape[-1]

            video_segments[out_frame_idx] = frame_masks
            sam2_masks = copy.deepcopy(frame_masks)

    """
    Step 5: save the tracking masks and json files
    """
    for frame_idx, frame_masks_info in video_segments.items():
        mask = frame_masks_info.labels
        mask_img = torch.zeros(frame_masks_info.mask_height, frame_masks_info.mask_width)
        for obj_id, obj_info in mask.items():
            # ğŸ”§ ç¡®ä¿maskå’Œmask_imgå°ºå¯¸åŒ¹é…
            if obj_info.mask.shape != mask_img.shape:
                #print(f"    âš ï¸  å¯¹è±¡{obj_id}çš„maskå°ºå¯¸ä¸åŒ¹é…: {obj_info.mask.shape} vs {mask_img.shape}")
                # è°ƒæ•´obj_info.maskå°ºå¯¸ä»¥åŒ¹é…mask_img
                if hasattr(obj_info.mask, 'cpu'):
                    mask_np = obj_info.mask.cpu().numpy()
                elif hasattr(obj_info.mask, 'numpy'):
                    mask_np = obj_info.mask.numpy()
                else:
                    mask_np = obj_info.mask
                mask_resized = cv2.resize(
                    mask_np.astype(np.uint8), 
                    (mask_img.shape[1], mask_img.shape[0]), 
                    interpolation=cv2.INTER_NEAREST
                ).astype(bool)
                obj_info.mask = torch.from_numpy(mask_resized)
            
            # ğŸ”§ ç¡®ä¿maskæ˜¯å¸ƒå°”ç±»å‹ç”¨äºç´¢å¼•ï¼Œå¤„ç†CUDA tensor
            if hasattr(obj_info.mask, 'cpu'):
                mask_bool = obj_info.mask.cpu().numpy().astype(bool)
            else:
                mask_bool = obj_info.mask.astype(bool)
            mask_img[mask_bool] = obj_id

        # ğŸ”§ å¤„ç†CUDA tensorè½¬æ¢ä¸ºnumpy
        if hasattr(mask_img, 'cpu'):
            mask_img = mask_img.cpu().numpy().astype(np.uint16)
        else:
            mask_img = mask_img.numpy().astype(np.uint16)
        np.save(os.path.join(mask_data_dir, frame_masks_info.mask_name), mask_img)

        json_data_path = os.path.join(json_data_dir, frame_masks_info.mask_name.replace(".npy", ".json"))
        frame_masks_info.to_json(json_data_path)
       

# æ³¨é‡Šæ‰ç¬¬ä¸€æ¬¡ç»˜åˆ¶ï¼Œå› ä¸ºåå‘è·Ÿè¸ªä¼šæ”¹è¿›ç»“æœï¼Œåªéœ€è¦æœ€ç»ˆç»“æœ
# CommonUtils.draw_masks_and_box_with_supervision(video_dir, mask_data_dir, json_data_dir, result_dir)

print("try reverse tracking")
start_object_id = 0
object_info_dict = {}
for frame_idx, current_object_count in frame_object_count.items():
    if frame_idx != 0:
        video_predictor.reset_state(inference_state)
        image_base_name = frame_names[frame_idx].split(".")[0]
        json_data_path = os.path.join(json_data_dir, f"mask_{image_base_name}.json")
        json_data = MaskDictionaryModel().from_json(json_data_path)
        mask_data_path = os.path.join(mask_data_dir, f"mask_{image_base_name}.npy")
        mask_array = np.load(mask_data_path)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°å¯¹è±¡éœ€è¦åå‘è·Ÿè¸ª
        has_new_objects = False
        for object_id in range(start_object_id+1, current_object_count+1):
            print("reverse tracking object", object_id)
            object_info_dict[object_id] = json_data.labels[object_id]
            video_predictor.add_new_mask(inference_state, frame_idx, object_id, mask_array == object_id)
            has_new_objects = True
        
        # åªæœ‰å½“æœ‰æ–°å¯¹è±¡æ—¶æ‰è¿›è¡Œåå‘è·Ÿè¸ª
        if has_new_objects:
            for out_frame_idx, out_obj_ids, out_mask_logits in video_predictor.propagate_in_video(inference_state, max_frame_num_to_track=step*2,  start_frame_idx=frame_idx, reverse=True):
                image_base_name = frame_names[out_frame_idx].split(".")[0]
                json_data_path = os.path.join(json_data_dir, f"mask_{image_base_name}.json")
                json_data = MaskDictionaryModel().from_json(json_data_path)
                mask_data_path = os.path.join(mask_data_dir, f"mask_{image_base_name}.npy")
                mask_array = np.load(mask_data_path)
                # merge the reverse tracking masks with the original masks
                for i, out_obj_id in enumerate(out_obj_ids):
                    out_mask = (out_mask_logits[i] > 0.0).cpu()
                    if out_mask.sum() == 0:
                        print("no mask for object", out_obj_id, "at frame", out_frame_idx)
                        continue
                    
                    object_info = object_info_dict[out_obj_id]
                    object_info.mask = out_mask[0]
                    
                    # ğŸ”§ ç¡®ä¿maskå’Œmask_arrayå°ºå¯¸åŒ¹é…ï¼ˆå…³é”®ä¿®å¤ï¼‰
                    if object_info.mask.shape != mask_array.shape:
                        # è°ƒæ•´object_info.maskå°ºå¯¸ä»¥åŒ¹é…mask_array
                        if object_info.mask.shape[0] != mask_array.shape[0] or object_info.mask.shape[1] != mask_array.shape[1]:
                            # ä½¿ç”¨OpenCV resizeè°ƒæ•´maskå°ºå¯¸
                            if hasattr(object_info.mask, 'cpu'):
                                mask_np = object_info.mask.cpu().numpy().astype(np.uint8)
                            else:
                                mask_np = object_info.mask.numpy().astype(np.uint8)
                            mask_resized = cv2.resize(
                                mask_np, 
                                (mask_array.shape[1], mask_array.shape[0]), 
                                interpolation=cv2.INTER_NEAREST
                            ).astype(bool)
                            object_info.mask = torch.from_numpy(mask_resized)
                    
                    # åº”ç”¨æ ‡ç­¾ä¸€è‡´æ€§
                    consistent_label = label_manager.get_consistent_label(out_obj_id, object_info.class_name, frame_idx=out_frame_idx)
                    if consistent_label != object_info.class_name:
                        print(f"  åå‘è·Ÿè¸ªæ ‡ç­¾ä¸€è‡´æ€§ä¿®æ­£: ç‰©ä½“ID {out_obj_id} {object_info.class_name} â†’ {consistent_label}")
                        object_info.class_name = consistent_label
                    
                    object_info.update_box()
                    json_data.labels[out_obj_id] = object_info
                    mask_array = np.where(mask_array != out_obj_id, mask_array, 0)
                    # ğŸ”§ ç¡®ä¿maskæ˜¯å¸ƒå°”ç±»å‹ç”¨äºç´¢å¼•ï¼Œå¤„ç†CUDA tensor
                    if hasattr(object_info.mask, 'cpu'):
                        mask_bool = object_info.mask.cpu().numpy().astype(bool)
                    elif hasattr(object_info.mask, 'numpy'):
                        mask_bool = object_info.mask.numpy().astype(bool)
                    else:
                        mask_bool = object_info.mask.astype(bool)
                    mask_array[mask_bool] = out_obj_id
                
                np.save(mask_data_path, mask_array)
                json_data.to_json(json_data_path)
        
    start_object_id = current_object_count

"""
Step 6: Draw the results and save the video
"""
# æ‰§è¡Œå…¨å±€æ ‡ç­¾ä¸€è‡´æ€§ä¼˜åŒ–
label_manager.force_label_consistency(json_data_dir, frame_names)

print("\nğŸ¨ å¼€å§‹ç»˜åˆ¶æœ€ç»ˆç»“æœ...")
print("ğŸ§¹ æ¸…ç©ºç»“æœç›®å½•...")
clear_directory(result_dir)
print("âœ… ç»“æœç›®å½•å·²æ¸…ç©º")

# ä½¿ç”¨åå‘è·Ÿè¸ªåçš„æ”¹è¿›ç»“æœ
CommonUtils.draw_masks_and_box_with_supervision(video_dir, mask_data_dir, json_data_dir, result_dir)

# ä½¿ç”¨è¾“å…¥è§†é¢‘çš„å¸§ç‡åˆ›å»ºè¾“å‡ºè§†é¢‘
print(f"ğŸ¬ ä½¿ç”¨è¾“å…¥è§†é¢‘å¸§ç‡ {input_video_fps:.2f} fps åˆ›å»ºè¾“å‡ºè§†é¢‘...")
create_video_from_images(result_dir, output_video_path, frame_rate=input_video_fps)

# è¾“å‡ºæœ€ç»ˆç»“æœè·¯å¾„ä¿¡æ¯
print("\nğŸ‰ è§†é¢‘åˆ†æå®Œæˆï¼")
print("="*60)
print(f"ï¿½ è¾“å…¥è§†é¢‘è·¯å¾„: {input_video_path}")
print(f"ğŸï¸  æå–å¸§æ•°æ®è·¯å¾„: {video_dir}")
print(f"ï¿½ğŸ“¸ æ³¨é‡Šå›¾åƒä¿å­˜è·¯å¾„: {result_dir}")
print(f"ğŸ¬ æœ€ç»ˆè§†é¢‘è¾“å‡ºè·¯å¾„: {output_video_path}")
print(f"ï¿½ è¾“å‡ºè§†é¢‘å¸§ç‡: {input_video_fps:.2f} fps (ä¸è¾“å…¥è§†é¢‘ä¸€è‡´)")
print(f"ï¿½ğŸ’¾ é®ç½©æ•°æ®ä¿å­˜è·¯å¾„: {mask_data_dir}")
print(f"ğŸ“„ JSONæ•°æ®ä¿å­˜è·¯å¾„: {json_data_dir}")
print(f"ğŸ“Š æ€»å…±å¤„ç†äº† {len(frame_names)} å¸§å›¾åƒ")
print("="*60)

# ç»Ÿè®¡holeæ£€æµ‹ç»“æœ
hole_stats = {"total_holes": 0, "frames_with_holes": 0}
for frame_name in frame_names:
    image_base_name = frame_name.split(".")[0]
    json_path = os.path.join(json_data_dir, f"mask_{image_base_name}.json")
    if os.path.exists(json_path):
        frame_data = MaskDictionaryModel().from_json(json_path)
        frame_holes = sum(1 for obj_info in frame_data.labels.values() if obj_info.class_name == 'hole')
        if frame_holes > 0:
            hole_stats["frames_with_holes"] += 1
            hole_stats["total_holes"] += frame_holes

print(f"\nğŸ” Holeæ£€æµ‹ç»Ÿè®¡:")
print(f"   - æ£€æµ‹åˆ°çš„holeæ€»æ•°: {hole_stats['total_holes']}")
print(f"   - åŒ…å«holeçš„å¸§æ•°: {hole_stats['frames_with_holes']}/{len(frame_names)}")
if len(frame_names) > 0:
    print(f"   - Holeæ£€å‡ºç‡: {hole_stats['frames_with_holes']/len(frame_names)*100:.1f}%")
print("="*60)